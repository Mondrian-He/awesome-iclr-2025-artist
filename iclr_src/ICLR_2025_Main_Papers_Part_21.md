# ICLR 2025 Main Conference Papers

**Summary:** 37 papers with extracted content:
- ðŸ“Š Total images: 46210
- ðŸ“‹ Total tables: 34695
- ðŸ“„ Total files: 80905

*Note: Equations have been filtered out and are not included.*

---

# ICLR 2025 Main Papers - Part 21 of 100

## ç›®å½• (Table of Contents)

1. [Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse](#Feature-Responsiveness-Scores-Model-Agnostic-Explanations-for-Recourse)
2. [A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation](#A-Spark-of-Vision-Language-Intelligence-2-Dimensional-Autoregressive-Transformer-for-Efficient-Finegrained-Image-Generation)
3. [GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians](#GaussianBlock-Building-Part-Aware-Compositional-and-Editable-3D-Scene-by-Primitives-and-Gaussians)
4. [Improving Instruction-Following in Language Models through Activation Steering](#Improving-Instruction-Following-in-Language-Models-through-Activation-Steering)
5. [Scaling Autonomous Agents via Automatic Reward Modeling And Planning](#Scaling-Autonomous-Agents-via-Automatic-Reward-Modeling-And-Planning)
6. [Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation](#Explaining-Modern-Gated-Linear-RNNs-via-a-Unified-Implicit-Attention-Formulation)
7. [PFDiff: Training-Free Acceleration of Diffusion Models Combining Past and Future Scores](#PFDiff-Training-Free-Acceleration-of-Diffusion-Models-Combining-Past-and-Future-Scores)
8. [Learning to Communicate Through Implicit Communication Channels](#Learning-to-Communicate-Through-Implicit-Communication-Channels)
9. [RESfM: Robust Deep Equivariant Structure from Motion](#RESfM-Robust-Deep-Equivariant-Structure-from-Motion)
10. [Video In-context Learning: Autoregressive Transformers are Zero-Shot Video Imitators](#Video-In-context-Learning-Autoregressive-Transformers-are-Zero-Shot-Video-Imitators)
11. [ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains](#ChroKnowledge-Unveiling-Chronological-Knowledge-of-Language-Models-in-Multiple-Domains)
12. [Aligning Visual Contrastive learning models via Preference Optimization](#Aligning-Visual-Contrastive-learning-models-via-Preference-Optimization)
13. [MGDA Converges under Generalized Smoothness, Provably](#MGDA-Converges-under-Generalized-Smoothness-Provably)
14. [Making Text Embedders Few-Shot Learners](#Making-Text-Embedders-Few-Shot-Learners)
15. [A Solvable Attention for Neural Scaling Laws](#A-Solvable-Attention-for-Neural-Scaling-Laws)
16. [ST-GCond: Self-supervised and Transferable Graph Dataset Condensation](#ST-GCond-Self-supervised-and-Transferable-Graph-Dataset-Condensation)
17. [Learning Successor Features with Distributed Hebbian Temporal Memory](#Learning-Successor-Features-with-Distributed-Hebbian-Temporal-Memory)
18. [Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct](#Inspection-and-Control-of-Self-Generated-Text-Recognition-Ability-in-Llama3-8b-Instruct)
19. [When GNNs meet symmetry in ILPs: an orbit-based feature augmentation approach](#When-GNNs-meet-symmetry-in-ILPs-an-orbit-based-feature-augmentation-approach)
20. [SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs](#SINGER-Stochastic-Network-Graph-Evolving-Operator-for-High-Dimensional-PDEs)
21. [FlashMask: Efficient and Rich Mask Extension of FlashAttention](#FlashMask-Efficient-and-Rich-Mask-Extension-of-FlashAttention)
22. [Towards Effective Evaluations and Comparisons for LLM Unlearning Methods](#Towards-Effective-Evaluations-and-Comparisons-for-LLM-Unlearning-Methods)
23. [On Calibration of LLM-based Guard Models for Reliable Content Moderation](#On-Calibration-of-LLM-based-Guard-Models-for-Reliable-Content-Moderation)
24. [TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting](#TimeKAN-KAN-based-Frequency-Decomposition-Learning-Architecture-for-Long-term-Time-Series-Forecasting)
25. [SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance](#SBSC-Step-by-Step-Coding-for-Improving-Mathematical-Olympiad-Performance)
26. [NRGBoost: Energy-Based Generative Boosted Trees](#NRGBoost-Energy-Based-Generative-Boosted-Trees)
27. [Process Reward Model with Q-value Rankings](#Process-Reward-Model-with-Q-value-Rankings)
28. [LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases](#LLM-based-Typed-Hyperresolution-for-Commonsense-Reasoning-with-Knowledge-Bases)
29. [Credit-based self organizing maps: training deep topographic networks with minimal performance degradation](#Credit-based-self-organizing-maps-training-deep-topographic-networks-with-minimal-performance-degradation)
30. [Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions](#Improved-Algorithms-for-Kernel-Matrix-Vector-Multiplication-Under-Sparsity-Assumptions)
31. [LancBiO: Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace](#LancBiO-Dynamic-Lanczos-aided-Bilevel-Optimization-via-Krylov-Subspace)
32. [Needle Threading: Can LLMs Follow Threads Through Near-Million-Scale Haystacks?](#Needle-Threading-Can-LLMs-Follow-Threads-Through-Near-Million-Scale-Haystacks)
33. [Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models](#Deep-Compression-Autoencoder-for-Efficient-High-Resolution-Diffusion-Models)
34. [Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrieval](#Learning-Fine-Grained-Representations-through-Textual-Token-Disentanglement-in-Composed-Video-Retrieval)
35. [SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation](#SaRA-High-Efficient-Diffusion-Model-Fine-tuning-with-Progressive-Sparse-Low-Rank-Adaptation)
36. [Tree of Attributes Prompt Learning for Vision-Language Models](#Tree-of-Attributes-Prompt-Learning-for-Vision-Language-Models)
37. [Expected Return Symmetries](#Expected-Return-Symmetries)

---


## Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse

### Images

![03f144c075a1c93a6c4a70d2863621b40a5e7ef8c70a6d1d0841225746136a41.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/03f144c075a1c93a6c4a70d2863621b40a5e7ef8c70a6d1d0841225746136a41.jpg)

![38c1f1ff4cf2c109eb6b05a001aecd5c07ae4c0256bbc95a58ed5fe7b8aacc63.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/38c1f1ff4cf2c109eb6b05a001aecd5c07ae4c0256bbc95a58ed5fe7b8aacc63.jpg)

![3b4203deb9525b12ed51929a557bf12f137685a69943a34f6c235cd24de64d7f.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/3b4203deb9525b12ed51929a557bf12f137685a69943a34f6c235cd24de64d7f.jpg)

![3c038405d4caec779ff41705634bd494f4dbac7310f4696b459c0a6b3ed42db6.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/3c038405d4caec779ff41705634bd494f4dbac7310f4696b459c0a6b3ed42db6.jpg)

![6c9dfe9f965c6ac8a80ca7772bd1826b25b9f3d9bf946773f5a724c577bac3d0.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/6c9dfe9f965c6ac8a80ca7772bd1826b25b9f3d9bf946773f5a724c577bac3d0.jpg)

![94713f686130bd502572cf6ece3eeb5bc9b8170351a50b64e362f576ef48239b.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/94713f686130bd502572cf6ece3eeb5bc9b8170351a50b64e362f576ef48239b.jpg)

![e5b3bdb999c40427e0fc6df8ad0f59ec76f6eb171f4c1f4798b02af919757007.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/images/e5b3bdb999c40427e0fc6df8ad0f59ec76f6eb171f4c1f4798b02af919757007.jpg)

### Tables

![3f1c6de879af5e1ff5130170b3aa6353f47aa3f41b04dfe437c79d64f7be28a0.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/3f1c6de879af5e1ff5130170b3aa6353f47aa3f41b04dfe437c79d64f7be28a0.jpg)

![74186576cf5163e23c766c8c29e70c398cd43194d1516d52a4bc2b2239cf0aa4.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/74186576cf5163e23c766c8c29e70c398cd43194d1516d52a4bc2b2239cf0aa4.jpg)

![94c4f18615d6776b0205dabd67c00936540d8a2d4703b00f42068c7ceec87a55.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/94c4f18615d6776b0205dabd67c00936540d8a2d4703b00f42068c7ceec87a55.jpg)

![bf997de8e0925a5723f7264cdf719b851d522b1bb1b3690211c497e5672f0b63.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/bf997de8e0925a5723f7264cdf719b851d522b1bb1b3690211c497e5672f0b63.jpg)

![e3c5acf51efe244822d9ab91e78fadb185a5177d04c6d3083ce49019e14dd665.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/e3c5acf51efe244822d9ab91e78fadb185a5177d04c6d3083ce49019e14dd665.jpg)

![ece4f7fbf73b1e71174d79070b4db017ca1f265fd7e8b2dbada7bbc40a33895a.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/ece4f7fbf73b1e71174d79070b4db017ca1f265fd7e8b2dbada7bbc40a33895a.jpg)

![f097c2b8326ba30b485d9d90743f6d942d5da238e773b3199904d3b9b026f7cc.jpg](../iclr_results/747_Learning Evolving Tools for Large Language Models/tables/f097c2b8326ba30b485d9d90743f6d942d5da238e773b3199904d3b9b026f7cc.jpg)

## Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse


### Images

![03491497c4898d3cc58c0e7871dd313720f7f3ee8dfb49d3118925cd4424f1ba.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/03491497c4898d3cc58c0e7871dd313720f7f3ee8dfb49d3118925cd4424f1ba.jpg)

![25fb40ef1cc3c5e59062cc2e63401179d7b801b46cb29240f66c6f3b9d1e09bd.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/25fb40ef1cc3c5e59062cc2e63401179d7b801b46cb29240f66c6f3b9d1e09bd.jpg)

![2ac6e698c31b2c70d780caa7c007a1f1934c90b1cf3ca5b4e5447ba1296fcd86.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/2ac6e698c31b2c70d780caa7c007a1f1934c90b1cf3ca5b4e5447ba1296fcd86.jpg)

![306cc311f2210ce005b88a04b9783d6acafac2ce1f5a89b935fdb5246a243906.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/306cc311f2210ce005b88a04b9783d6acafac2ce1f5a89b935fdb5246a243906.jpg)

![3441bbc01ada56f478a9d41c3c99c8d095cd7df165fa7f20181e7d670e84c564.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/3441bbc01ada56f478a9d41c3c99c8d095cd7df165fa7f20181e7d670e84c564.jpg)

![3ea0709722317ce361d0682467a238be0fa8d490a3ebac914287e36a4a4e1704.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/3ea0709722317ce361d0682467a238be0fa8d490a3ebac914287e36a4a4e1704.jpg)

![46054ce6b953ef793a2ac5dc345662195a3274064b69d505e7187a4abebd2815.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/46054ce6b953ef793a2ac5dc345662195a3274064b69d505e7187a4abebd2815.jpg)

![5d68fc40438a416e3ce95d6ce874ceb57eb64eb54743ec3a2969acd08036eede.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/5d68fc40438a416e3ce95d6ce874ceb57eb64eb54743ec3a2969acd08036eede.jpg)

![707eba7e4c26ed69361d5df82a71b7ae8a8c9b4cb586bb1dad0312abf05d5ca0.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/707eba7e4c26ed69361d5df82a71b7ae8a8c9b4cb586bb1dad0312abf05d5ca0.jpg)

![7a486169330ae32db0e8ab5227fada766b352bb412ea7b4b9c4d09f75ba042b7.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/7a486169330ae32db0e8ab5227fada766b352bb412ea7b4b9c4d09f75ba042b7.jpg)

![9f30d655c8af8b681816968aa2d66eba1f8b579b5c090efb2b6bf3e9f6b8d2e2.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/9f30d655c8af8b681816968aa2d66eba1f8b579b5c090efb2b6bf3e9f6b8d2e2.jpg)

![9f71abccdea4ba41bd9de9869bd4b8cec81a6de653494427af95c867ff12ed43.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/9f71abccdea4ba41bd9de9869bd4b8cec81a6de653494427af95c867ff12ed43.jpg)

![f0248889618f4251fbfb180109e4358204cc7a28dd7bd86eabbba36e6805fdf7.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/images/f0248889618f4251fbfb180109e4358204cc7a28dd7bd86eabbba36e6805fdf7.jpg)

### Tables

![156b313a0399d5f831c2769ec1c9c0dcf81d9a41429b3cfc59f8059a5e430eba.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/156b313a0399d5f831c2769ec1c9c0dcf81d9a41429b3cfc59f8059a5e430eba.jpg)

![1e5a2e36a50389372bb1f41d881471b2a3a268e45109236621bec018abc93fe2.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/1e5a2e36a50389372bb1f41d881471b2a3a268e45109236621bec018abc93fe2.jpg)

![2c42e2bae70942016480ce14ec053c1385f527b6f5ddef3651ef6b605ecb94ac.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/2c42e2bae70942016480ce14ec053c1385f527b6f5ddef3651ef6b605ecb94ac.jpg)

![456822990166799cb7679a72c1b099738426412c121bce5eac840e17136a9ec4.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/456822990166799cb7679a72c1b099738426412c121bce5eac840e17136a9ec4.jpg)

![4df58d232c81e029e26295f711373b8a71e263fd55263d1c8f763140461c9802.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/4df58d232c81e029e26295f711373b8a71e263fd55263d1c8f763140461c9802.jpg)

![7d946406a72a57cfec0d2a7c65607a180a0d8f55a4df43f957705e48c8bc51c9.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/7d946406a72a57cfec0d2a7c65607a180a0d8f55a4df43f957705e48c8bc51c9.jpg)

![9d7ec61bebb465616866103810edfcb25bb9d82df930ace7aeab71188ae2953e.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/9d7ec61bebb465616866103810edfcb25bb9d82df930ace7aeab71188ae2953e.jpg)

![a04012c8082663fc928bd9afc25e58ade9cd05515bfda94f0d17c1cf26886295.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/a04012c8082663fc928bd9afc25e58ade9cd05515bfda94f0d17c1cf26886295.jpg)

![bc431f1fde47c19420f0da09718f0fde2469a50738018809a383c3383fb21b13.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/bc431f1fde47c19420f0da09718f0fde2469a50738018809a383c3383fb21b13.jpg)

![c7d170c3958003f66ca18f3d860b8e6ec765c5482abdd173ec2120d8ca6f67dc.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/c7d170c3958003f66ca18f3d860b8e6ec765c5482abdd173ec2120d8ca6f67dc.jpg)

![d2d7982436eeacb4af66e2702cb3342b0e7bfe752f195d843fd022ea27158b98.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/d2d7982436eeacb4af66e2702cb3342b0e7bfe752f195d843fd022ea27158b98.jpg)

![deaca709ea9cf7c8001b8993669d0fece7d5a12d14c099b91096d13f4a48c2ad.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/deaca709ea9cf7c8001b8993669d0fece7d5a12d14c099b91096d13f4a48c2ad.jpg)

![f94dae5e5f7fed715973483313b3d7a979bda8b8c4047ac58edbca773409404d.jpg](../iclr_results/748_Feature Responsiveness Scores_ Model-Agnostic Explanations for Recourse/tables/f94dae5e5f7fed715973483313b3d7a979bda8b8c4047ac58edbca773409404d.jpg)

## A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation


### Images

![00d47adcf71a47d7c633f561644e6c7facf9513a10198f9b9423370cd9a82a8d.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/00d47adcf71a47d7c633f561644e6c7facf9513a10198f9b9423370cd9a82a8d.jpg)

![0e59d5fa742eb5854b859eb7ddac51ae2c72168b768bf298933ea29da39578cb.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/0e59d5fa742eb5854b859eb7ddac51ae2c72168b768bf298933ea29da39578cb.jpg)

![1576a7461c762927870192109b6017cb691cd1cd3009657fe6ffba1aff288942.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/1576a7461c762927870192109b6017cb691cd1cd3009657fe6ffba1aff288942.jpg)

![197c270f616c9b3f39ef42137a4ed482769f58f6699e98ee6b55d50eb352d4a9.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/197c270f616c9b3f39ef42137a4ed482769f58f6699e98ee6b55d50eb352d4a9.jpg)

![23544cd43f87e6765e3e188651f41bc19e49832d469ac16fa6bd5aef4ce3f1d3.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/23544cd43f87e6765e3e188651f41bc19e49832d469ac16fa6bd5aef4ce3f1d3.jpg)

![26b215fa9278a32bf77d50581c2c157fd6dabb9d61b20515e2abc0cde360cff7.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/26b215fa9278a32bf77d50581c2c157fd6dabb9d61b20515e2abc0cde360cff7.jpg)

![3178ce387f93e0642d841ac4bc3a783a7ba8bfaba51604c8361be84b0ef4cba2.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/3178ce387f93e0642d841ac4bc3a783a7ba8bfaba51604c8361be84b0ef4cba2.jpg)

![40109a0ef73110c75a9cebb38c57fb39b271a66b9e811b939f6b5c41d27ee7bb.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/40109a0ef73110c75a9cebb38c57fb39b271a66b9e811b939f6b5c41d27ee7bb.jpg)

![5807d4c1f860624022024242366bc995b6d39767fc21a463bc16805548096ccd.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/5807d4c1f860624022024242366bc995b6d39767fc21a463bc16805548096ccd.jpg)

![5d49425e7df331bcab42e1267b11e16fa701dd954f98641c8f8b5161e141c166.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/5d49425e7df331bcab42e1267b11e16fa701dd954f98641c8f8b5161e141c166.jpg)

![63f791f013e7dd4875a4a290bab2e35084934cdc41bcc18f75d2cbe116718b21.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/63f791f013e7dd4875a4a290bab2e35084934cdc41bcc18f75d2cbe116718b21.jpg)

![644c1b281c09b68f4dad1cc01e3bb77545e3b4300bc7f4295de6873903d39c05.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/644c1b281c09b68f4dad1cc01e3bb77545e3b4300bc7f4295de6873903d39c05.jpg)

![72bc5df48dbbaf7e2bc0f2b4c4baf9561d6c147e499abf6e20c5ccb2b9387896.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/72bc5df48dbbaf7e2bc0f2b4c4baf9561d6c147e499abf6e20c5ccb2b9387896.jpg)

![84ad82b39ca980b8cfc743234c17791cb21f565dacc8637ee044eaf81b365065.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/84ad82b39ca980b8cfc743234c17791cb21f565dacc8637ee044eaf81b365065.jpg)

![8fb482ddafaf3102da57237b5b89f825777ede9426476cac0a741c054ef89ece.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/8fb482ddafaf3102da57237b5b89f825777ede9426476cac0a741c054ef89ece.jpg)

![a3972bea4281abdcda6638e77168b5d047148aa88719f849c6eca4abc28e9399.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/a3972bea4281abdcda6638e77168b5d047148aa88719f849c6eca4abc28e9399.jpg)

![b23dd030f13db8b9c1ebe8952f7b2a1952f59e61649d2fd01a3146d15a67a393.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/b23dd030f13db8b9c1ebe8952f7b2a1952f59e61649d2fd01a3146d15a67a393.jpg)

![c0f2c36ff883bca6d882db8e294e583f2de991cae1dd10c89eb3305e98f782f7.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/c0f2c36ff883bca6d882db8e294e583f2de991cae1dd10c89eb3305e98f782f7.jpg)

![c3942aefb8fffaa56db7d87d96fe88dc5ea3e378215a26efcc512e54aafd8f44.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/c3942aefb8fffaa56db7d87d96fe88dc5ea3e378215a26efcc512e54aafd8f44.jpg)

![da6af6aa22ecbed21be97aca144ed09fb6e66271ba1161dc7e50b900ab852d5b.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/da6af6aa22ecbed21be97aca144ed09fb6e66271ba1161dc7e50b900ab852d5b.jpg)

![e73935b0279114e1cf7b0a9109123e225573a3c3184265d68c75b3dc1bc7344b.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/e73935b0279114e1cf7b0a9109123e225573a3c3184265d68c75b3dc1bc7344b.jpg)

![fd2ad4e199a8b9b9f68560c4b71dfbc2a6a7c8e71b2dda40ba8c0118612cceaf.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/fd2ad4e199a8b9b9f68560c4b71dfbc2a6a7c8e71b2dda40ba8c0118612cceaf.jpg)

![fe8955472bf2b7e2e81f5f3cea50c09a691dde8dce7a71fd4c0d58571381d5ab.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/images/fe8955472bf2b7e2e81f5f3cea50c09a691dde8dce7a71fd4c0d58571381d5ab.jpg)

### Tables

![0d11443dc94b1dcc9dd5757c9ae1b73fb61618e665b809f13ef5b8a55a0b6a82.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/0d11443dc94b1dcc9dd5757c9ae1b73fb61618e665b809f13ef5b8a55a0b6a82.jpg)

![2833c3995bb56e7d17ce6da8c26a0e1c57d53b7db58b7df985af87362470d900.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/2833c3995bb56e7d17ce6da8c26a0e1c57d53b7db58b7df985af87362470d900.jpg)

![2d98949373166934e27421eb2391589b5be45a68d2a2fd0babc727f27a919d2c.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/2d98949373166934e27421eb2391589b5be45a68d2a2fd0babc727f27a919d2c.jpg)

![2fb0626ac1d7ae8584582168438c6e9ed6a91ee5716e5b917f886f5e16952cb5.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/2fb0626ac1d7ae8584582168438c6e9ed6a91ee5716e5b917f886f5e16952cb5.jpg)

![32a911ddac735bcc55e5f5273fdf54c674030e4631746b4c8fac2b55184af987.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/32a911ddac735bcc55e5f5273fdf54c674030e4631746b4c8fac2b55184af987.jpg)

![55c61563d153782fdbe6283cf986431ff49318bb552780bab12135047e3a10e4.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/55c61563d153782fdbe6283cf986431ff49318bb552780bab12135047e3a10e4.jpg)

![6dc0b5794a9898ec7c13f731d4586ba3fd3fd3b62cd36cdd0e5a7b6c93c1d975.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/6dc0b5794a9898ec7c13f731d4586ba3fd3fd3b62cd36cdd0e5a7b6c93c1d975.jpg)

![6f86cfc6bab7c9f8918e348d835f674d9d7381b826deb39dd618b1375d70f63f.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/6f86cfc6bab7c9f8918e348d835f674d9d7381b826deb39dd618b1375d70f63f.jpg)

![b3d734839e55b0e1490fa4c54684259ccee889cef56ff4b4433076b4d0eecfec.jpg](../iclr_results/749_A Spark of Vision-Language Intelligence_ 2-Dimensional Autoregressive Transformer for Efficient Fine/tables/b3d734839e55b0e1490fa4c54684259ccee889cef56ff4b4433076b4d0eecfec.jpg)

## GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians


### Images

![0ef18fbbb6a7877c47f544df4163f4cc9906e37173693a6a5c670c5b642c95bd.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/0ef18fbbb6a7877c47f544df4163f4cc9906e37173693a6a5c670c5b642c95bd.jpg)

![1181b88e2967536866f744ab6da33105ae1f92dd8a85b6c5518ba8b5a0ede2d1.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/1181b88e2967536866f744ab6da33105ae1f92dd8a85b6c5518ba8b5a0ede2d1.jpg)

![166a4fec7efea23e022d85911688d437f01ca060bd65ba34ff68fab0f9e01a24.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/166a4fec7efea23e022d85911688d437f01ca060bd65ba34ff68fab0f9e01a24.jpg)

![1fd71c03224a78788b275c37ccd742ec0b0e40ec0983538acb4e58eee223d132.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/1fd71c03224a78788b275c37ccd742ec0b0e40ec0983538acb4e58eee223d132.jpg)

![43b2c22d7b2e2edca7b00e89b0de1e55336491407d603525d8cbdb5686cca8b2.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/43b2c22d7b2e2edca7b00e89b0de1e55336491407d603525d8cbdb5686cca8b2.jpg)

![98a36ef5da9ab21c140666641478e256085659492fcf725bd36086049c52c9cb.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/98a36ef5da9ab21c140666641478e256085659492fcf725bd36086049c52c9cb.jpg)

![99209c7a1799edab48c23c6314493ca466583301e6e19eb85a09062a7a6d7609.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/99209c7a1799edab48c23c6314493ca466583301e6e19eb85a09062a7a6d7609.jpg)

![a59314aedb9fcb0e4cb3e1e8e545b90d47c67dee1fc129dc01c5ad8f26ff845a.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/a59314aedb9fcb0e4cb3e1e8e545b90d47c67dee1fc129dc01c5ad8f26ff845a.jpg)

![f22069cfdf8fa3a070004e63ab3f3e5506c546cf650bb12901a0584803180814.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/images/f22069cfdf8fa3a070004e63ab3f3e5506c546cf650bb12901a0584803180814.jpg)

### Tables

![190dd90647313eab2d78f08f538c26260bea6b50fd7ac72637800f339946de88.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/tables/190dd90647313eab2d78f08f538c26260bea6b50fd7ac72637800f339946de88.jpg)

![4972729f5cffb7471e3c2cab542d7e33528898ca9c05b3313645f96ed39e1411.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/tables/4972729f5cffb7471e3c2cab542d7e33528898ca9c05b3313645f96ed39e1411.jpg)

![80f0933a4326afbd1133cb202afda18ded74776b85664e53a7796fc86530f69c.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/tables/80f0933a4326afbd1133cb202afda18ded74776b85664e53a7796fc86530f69c.jpg)

![b7cc82df358c71d1fd89068f3ae1152021aa3945e006da8dfba90c8d61c59b2c.jpg](../iclr_results/750_GaussianBlock_ Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians/tables/b7cc82df358c71d1fd89068f3ae1152021aa3945e006da8dfba90c8d61c59b2c.jpg)

## Improving Instruction-Following in Language Models through Activation Steering


### Images

![00de12729b2f187ce8c4d5fbe65469965a581e162672e46dbb537ad4bc579ce2.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/00de12729b2f187ce8c4d5fbe65469965a581e162672e46dbb537ad4bc579ce2.jpg)

![01905a01f4dff12d89b687980b695f9addf177f869d5ba2eb5cbe06131a41bb6.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/01905a01f4dff12d89b687980b695f9addf177f869d5ba2eb5cbe06131a41bb6.jpg)

![22336a70853416a8b0e85a84037df15522a01045fb738a70ecddd9ca20ec3e23.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/22336a70853416a8b0e85a84037df15522a01045fb738a70ecddd9ca20ec3e23.jpg)

![25a47b041cfe672b22908aaa3d7988a19f9f9c8e8adbec17f76fbe5150479c3c.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/25a47b041cfe672b22908aaa3d7988a19f9f9c8e8adbec17f76fbe5150479c3c.jpg)

![2e996082966261d7f113a2c14b7c9d5eb98921739d5ee756b424cd2c51d66d17.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/2e996082966261d7f113a2c14b7c9d5eb98921739d5ee756b424cd2c51d66d17.jpg)

![44fee7c6ce7319f2c88952eabaec738f09e6b5d1a43749fc369329a19b4cb2b6.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/44fee7c6ce7319f2c88952eabaec738f09e6b5d1a43749fc369329a19b4cb2b6.jpg)

![453b52be038bd34fc97fd5808e1bd9b442d62a0eae6fef9122afaba40bc5cef0.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/453b52be038bd34fc97fd5808e1bd9b442d62a0eae6fef9122afaba40bc5cef0.jpg)

![5209b4119084ff6d9e81964ad102ee552daf87336154cd74c73f838f8595543e.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/5209b4119084ff6d9e81964ad102ee552daf87336154cd74c73f838f8595543e.jpg)

![5571c9a47d82eca3df71a372dbec1567d90b01089797993ae5dd2fc4f65c5b3f.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/5571c9a47d82eca3df71a372dbec1567d90b01089797993ae5dd2fc4f65c5b3f.jpg)

![584d2af1007d05a649925b0f7bfc3db873613e419712137a6d1040ec988bbcf2.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/584d2af1007d05a649925b0f7bfc3db873613e419712137a6d1040ec988bbcf2.jpg)

![6577e441f33d2fff843af7c621022e8544128110e99503658f9cd56090dc3025.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/6577e441f33d2fff843af7c621022e8544128110e99503658f9cd56090dc3025.jpg)

![80ecf8908dcbe81e471e6c3ea835cd34ef5975ddaa14a1bf721e5bb04a79a512.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/80ecf8908dcbe81e471e6c3ea835cd34ef5975ddaa14a1bf721e5bb04a79a512.jpg)

![851d936905764e841f9cba99990235e41fe2a8c1ca7c8a39fb44d8512ce87d32.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/851d936905764e841f9cba99990235e41fe2a8c1ca7c8a39fb44d8512ce87d32.jpg)

![868284a36f9aa68bc5a27b76b31aa2b92621f76292f2e674faeea3dbb7658466.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/868284a36f9aa68bc5a27b76b31aa2b92621f76292f2e674faeea3dbb7658466.jpg)

![96e375bfa6d14c855e95813357aeeb380fe198e522077ac7adb9d4c405c5808d.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/96e375bfa6d14c855e95813357aeeb380fe198e522077ac7adb9d4c405c5808d.jpg)

![a080565debf253b2941f0cf66ee906cb1aa87a299909278c2891453042b1cef5.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/a080565debf253b2941f0cf66ee906cb1aa87a299909278c2891453042b1cef5.jpg)

![a85c7641ec9e3aa90e5eeb0b7740d35d2447e9cc513cafc55bf75c466132ecc4.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/a85c7641ec9e3aa90e5eeb0b7740d35d2447e9cc513cafc55bf75c466132ecc4.jpg)

![cef463531bb2f3564de2014e5f0f990a32183bfdf9408c06b0462685199d46ae.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/cef463531bb2f3564de2014e5f0f990a32183bfdf9408c06b0462685199d46ae.jpg)

![def4604bbe698d32b51682b0b42ac06512e129820b29812441220075e93fc9f1.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/images/def4604bbe698d32b51682b0b42ac06512e129820b29812441220075e93fc9f1.jpg)

### Tables

![412771d6f4ea5ade6eef8cde3ffbfa21d7724b798425ceaf227c456b94412bce.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/412771d6f4ea5ade6eef8cde3ffbfa21d7724b798425ceaf227c456b94412bce.jpg)

![56e171960612edf5dd61bbd92bb653fb3436a827c258a61b40ea6d192637ab0a.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/56e171960612edf5dd61bbd92bb653fb3436a827c258a61b40ea6d192637ab0a.jpg)

![708666886d8330e7fcc9ba939d095575b781fee30572633c5ecb39eeea890736.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/708666886d8330e7fcc9ba939d095575b781fee30572633c5ecb39eeea890736.jpg)

![92ea46c75390492c6c255cbbee96f536432d256d3f5638fd431ea8b57822d49f.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/92ea46c75390492c6c255cbbee96f536432d256d3f5638fd431ea8b57822d49f.jpg)

![9ea9dcea5d55be156281a29fc78b49014cda6f912044e7780ac7dd8e4a5acf0e.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/9ea9dcea5d55be156281a29fc78b49014cda6f912044e7780ac7dd8e4a5acf0e.jpg)

![c4e5728008feea48534e4a1bd36baebfb2e403d384c9a4bd6069911b50d98e36.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/c4e5728008feea48534e4a1bd36baebfb2e403d384c9a4bd6069911b50d98e36.jpg)

![cce17e5a7f31b8d4a7d7c53a5a732737d2bbfdb53caa71ae7d6c0756975ebda9.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/cce17e5a7f31b8d4a7d7c53a5a732737d2bbfdb53caa71ae7d6c0756975ebda9.jpg)

![d3157e4fb190465ac5782be4d7969e67d1c0b8c593a4e0d7b94a74d8970da346.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/d3157e4fb190465ac5782be4d7969e67d1c0b8c593a4e0d7b94a74d8970da346.jpg)

![d600e0111991598fc651abfd945315968d2d90ebdfe988b486d70d6feee721ed.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/d600e0111991598fc651abfd945315968d2d90ebdfe988b486d70d6feee721ed.jpg)

![d7309527e99f8a0e4e65c67a339865d573759281d8727650b19b32816e355fe6.jpg](../iclr_results/751_Improving Instruction-Following in Language Models through Activation Steering/tables/d7309527e99f8a0e4e65c67a339865d573759281d8727650b19b32816e355fe6.jpg)

## Scaling Autonomous Agents via Automatic Reward Modeling And Planning


### Images

![39d169a903cb2057afb75ad0272f5269a28567cee07548b67b537de9a50bc66b.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/39d169a903cb2057afb75ad0272f5269a28567cee07548b67b537de9a50bc66b.jpg)

![4317c50ec9a1a83f5802e13213682c83d2acd94c2e060a6c2dd5caebffc76446.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/4317c50ec9a1a83f5802e13213682c83d2acd94c2e060a6c2dd5caebffc76446.jpg)

![6f3202a1513916fa29904b2de0c9bf4224eda9b3b4ff5e6a009025dd9dc1c249.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/6f3202a1513916fa29904b2de0c9bf4224eda9b3b4ff5e6a009025dd9dc1c249.jpg)

![6f766a586956fbfb660978815ccf710d546cc9339efadca9d079c3ede4223ed8.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/6f766a586956fbfb660978815ccf710d546cc9339efadca9d079c3ede4223ed8.jpg)

![70b4d51e1bb56b7bf83ccff51ac4db7fdeddbc5d6037f4854125c82c1079c7bd.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/70b4d51e1bb56b7bf83ccff51ac4db7fdeddbc5d6037f4854125c82c1079c7bd.jpg)

![73618b240d258ef45345c1c453a201be4855f60210cd002f310e59f9b8a8de74.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/73618b240d258ef45345c1c453a201be4855f60210cd002f310e59f9b8a8de74.jpg)

![9f48ab6ff3788c0bf76f2748374062e6dbd55a1b66a24ad940ccd49e1fbc1abd.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/9f48ab6ff3788c0bf76f2748374062e6dbd55a1b66a24ad940ccd49e1fbc1abd.jpg)

![ac081164e5ca2f80359c9e78f65fb20cb6b777183acfb465f9adb70514f9bbbe.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/ac081164e5ca2f80359c9e78f65fb20cb6b777183acfb465f9adb70514f9bbbe.jpg)

![ae05cc8ccacac18d86be9c7647e57cd070edfee8f2ed3352b39ae028d47353ed.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/ae05cc8ccacac18d86be9c7647e57cd070edfee8f2ed3352b39ae028d47353ed.jpg)

![b1f58a6358f364477994c8129a5688559b2f71ac17d848f21cd4a550d0a0aa34.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/b1f58a6358f364477994c8129a5688559b2f71ac17d848f21cd4a550d0a0aa34.jpg)

![ba05077066f32225fd8853f914d0422ed51871ac5654bd30ea4e6bd2f796f1d2.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/ba05077066f32225fd8853f914d0422ed51871ac5654bd30ea4e6bd2f796f1d2.jpg)

![d58e84fc87d46369b96c7a977e2c719125dc0e78b0fb19f312585a419d782492.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/d58e84fc87d46369b96c7a977e2c719125dc0e78b0fb19f312585a419d782492.jpg)

![e7621fe1c3976703c0c05f1a9c162aa8630356e29d294d858282eecba69c93e7.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/images/e7621fe1c3976703c0c05f1a9c162aa8630356e29d294d858282eecba69c93e7.jpg)

### Tables

![258860ca8d34ef2376b02697649739876df69ad927249d71cd13ce7802b229be.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/258860ca8d34ef2376b02697649739876df69ad927249d71cd13ce7802b229be.jpg)

![2c044db2a9414d6a0eb94ed592c601a969e755039be1d8cf7daefa2bd290dcf1.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/2c044db2a9414d6a0eb94ed592c601a969e755039be1d8cf7daefa2bd290dcf1.jpg)

![6a33fcbcc5fb9f24483d9065d23bb24cf55f00be1f20107c3fe609f9bd1989f3.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/6a33fcbcc5fb9f24483d9065d23bb24cf55f00be1f20107c3fe609f9bd1989f3.jpg)

![6b31e16f7f29512b3666e58fc84178bc575a6f950a2fd684e11f057376841844.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/6b31e16f7f29512b3666e58fc84178bc575a6f950a2fd684e11f057376841844.jpg)

![8a9117041b4f1df1a5c2a353c748039e0cb338309acaeadb89a202f6507d1506.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/8a9117041b4f1df1a5c2a353c748039e0cb338309acaeadb89a202f6507d1506.jpg)

![98a0ccde1f987d848bf687b00dabf205919c6b9aa77351259a2ae1a66d6919ba.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/98a0ccde1f987d848bf687b00dabf205919c6b9aa77351259a2ae1a66d6919ba.jpg)

![a74c3d0546cea95a6cd0f99fb8428dd32d11e3b818bcb9cc047d4df10932a96e.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/a74c3d0546cea95a6cd0f99fb8428dd32d11e3b818bcb9cc047d4df10932a96e.jpg)

![a86b8cec4220304b6ed8b506b9c5cb24201e895649554d4cbb9882353371bd09.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/a86b8cec4220304b6ed8b506b9c5cb24201e895649554d4cbb9882353371bd09.jpg)

![afba76721318d52ca9c38e7c622fd56c759f342115ceeb638105abb18e4d5b07.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/afba76721318d52ca9c38e7c622fd56c759f342115ceeb638105abb18e4d5b07.jpg)

![c2778a17716cb07f5aae5464ec41ea595a75a6f5217c151ef397c021f01094b8.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/c2778a17716cb07f5aae5464ec41ea595a75a6f5217c151ef397c021f01094b8.jpg)

![d156909750c6202122ce7f8cdef05996764e53174d37e83947f6cdaa7d962257.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/d156909750c6202122ce7f8cdef05996764e53174d37e83947f6cdaa7d962257.jpg)

![e3ff0e18f217c1ea1b17b87a03ab8a3759e3c44c6ccfb6480338a43ee5bf81c2.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/e3ff0e18f217c1ea1b17b87a03ab8a3759e3c44c6ccfb6480338a43ee5bf81c2.jpg)

![eee13298797eccc14d82d82a19f46315cbe9a7975f10e1a3f8a2e3b2f9f84e7e.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/eee13298797eccc14d82d82a19f46315cbe9a7975f10e1a3f8a2e3b2f9f84e7e.jpg)

![f040ef3fa346d51f604e08c5794a9da7af1eb334af34f863587bfa424c476fda.jpg](../iclr_results/752_Scaling Autonomous Agents via Automatic Reward Modeling And Planning/tables/f040ef3fa346d51f604e08c5794a9da7af1eb334af34f863587bfa424c476fda.jpg)

## Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation


### Images

![1b6070e59e9fd0518295b06024561faf5fa048d083640a3d1bb0f96c61058777.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/1b6070e59e9fd0518295b06024561faf5fa048d083640a3d1bb0f96c61058777.jpg)

![227d608927e02bb511b90f0abdaa65fea16f2647264af65ebef726f6e81f8f04.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/227d608927e02bb511b90f0abdaa65fea16f2647264af65ebef726f6e81f8f04.jpg)

![550a8cc5ffdf08c1d287f137d1a7bffaa109757bcd3e70c0fe2ea65dd187a898.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/550a8cc5ffdf08c1d287f137d1a7bffaa109757bcd3e70c0fe2ea65dd187a898.jpg)

![5824083eab0d936254fdb4ecd9b55ce7c397f380f2799b10474af0fe8bcfea1a.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/5824083eab0d936254fdb4ecd9b55ce7c397f380f2799b10474af0fe8bcfea1a.jpg)

![5e7f66489038c0a7c4bd7c7eee55beeee127a8e2ce9f79dd8c0ee1ddbd2a2701.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/5e7f66489038c0a7c4bd7c7eee55beeee127a8e2ce9f79dd8c0ee1ddbd2a2701.jpg)

![eac0db31f279af9176eb24434c046fd2abc56588bf8d4dfc632624578e86fbd5.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/images/eac0db31f279af9176eb24434c046fd2abc56588bf8d4dfc632624578e86fbd5.jpg)

### Tables

![173cb96da1d6b98b15179b61c2b315823a119afc36e3cec49d7360822b7006bd.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/173cb96da1d6b98b15179b61c2b315823a119afc36e3cec49d7360822b7006bd.jpg)

![317c3f779f99a80b34700f5b8804b22c6386a44316aa2bc432a196af1a6770c7.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/317c3f779f99a80b34700f5b8804b22c6386a44316aa2bc432a196af1a6770c7.jpg)

![3f5ae598480d3437fd1c1171ebb8a86c8e45205d0aa0409ce54e080a3453f448.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/3f5ae598480d3437fd1c1171ebb8a86c8e45205d0aa0409ce54e080a3453f448.jpg)

![636695b566bce3aeda2e6af07afbeef9ef906a76ba47564c0e43b7ddf45d5871.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/636695b566bce3aeda2e6af07afbeef9ef906a76ba47564c0e43b7ddf45d5871.jpg)

![e890cd17eadbfdeb68ab0d138888b63105ad51c1fb57f226d5984d0d2b149b3b.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/e890cd17eadbfdeb68ab0d138888b63105ad51c1fb57f226d5984d0d2b149b3b.jpg)

![f7c7553c98be1cfc2567f3441136c940de6a68e10d20cf173c1c7ac03714382b.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/f7c7553c98be1cfc2567f3441136c940de6a68e10d20cf173c1c7ac03714382b.jpg)

![fdb9dcd07ba551fb372d903eb38a921af850301780715f770a55a54dd79d7277.jpg](../iclr_results/753_Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation/tables/fdb9dcd07ba551fb372d903eb38a921af850301780715f770a55a54dd79d7277.jpg)

## PFDiff: Training-Free Acceleration of Diffusion Models Combining Past and Future Scores


### Images

![270a8a7b9f30fdb59ff115cfea76c717736e27b4b8702e875546bc19d9f6e3a2.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/270a8a7b9f30fdb59ff115cfea76c717736e27b4b8702e875546bc19d9f6e3a2.jpg)

![463269d9e60e1c172cfcb5b23d0e7e1d564c9bf3da8e519ebb986a61947ab9bf.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/463269d9e60e1c172cfcb5b23d0e7e1d564c9bf3da8e519ebb986a61947ab9bf.jpg)

![64e22a91c1404d1228eb837d85e9a1b6ee6117bd2962da977e2ad655f5a8a269.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/64e22a91c1404d1228eb837d85e9a1b6ee6117bd2962da977e2ad655f5a8a269.jpg)

![86549d208db2758dfe72fd42124c38850a18cb04685d86b2ef381223f5f4b5a6.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/86549d208db2758dfe72fd42124c38850a18cb04685d86b2ef381223f5f4b5a6.jpg)

![9bef3321ffc66140d87b88e1b63f90bed2d923bb33ba88f3f938e744a9b421f1.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/9bef3321ffc66140d87b88e1b63f90bed2d923bb33ba88f3f938e744a9b421f1.jpg)

![9c81f20fae3a8ff0543c64a8860a3c172ff1d319c0dc8f9dffeb7cae0c52590a.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/9c81f20fae3a8ff0543c64a8860a3c172ff1d319c0dc8f9dffeb7cae0c52590a.jpg)

![a216decb71ae92c7ae6ee3a4f0f7ef1bae0c26d72f3be7a459375adf57481c7d.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/a216decb71ae92c7ae6ee3a4f0f7ef1bae0c26d72f3be7a459375adf57481c7d.jpg)

![a74e61e978baf13ca20fc1fa174a0617eed5e5667b841edb9ac8a4d7dc6779a6.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/a74e61e978baf13ca20fc1fa174a0617eed5e5667b841edb9ac8a4d7dc6779a6.jpg)

![b088dd5ce4b03ab731788375e8e88a7166bffb6b0956213ca4bfe1385dde1a6a.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/b088dd5ce4b03ab731788375e8e88a7166bffb6b0956213ca4bfe1385dde1a6a.jpg)

![bea74cd7bba9695949ceaa6727916e1fa6d360b58cb5ec9756e266627f78edb9.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/bea74cd7bba9695949ceaa6727916e1fa6d360b58cb5ec9756e266627f78edb9.jpg)

![bf1ed8031ae5ad1887d2416dc70043da5535e2e44424e82b309efc4a6391d32c.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/bf1ed8031ae5ad1887d2416dc70043da5535e2e44424e82b309efc4a6391d32c.jpg)

![e18751910ebc96345edae9f385721cb037fc22fadfef6935f10d7a414929ed1e.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/e18751910ebc96345edae9f385721cb037fc22fadfef6935f10d7a414929ed1e.jpg)

![e6eb27e763b09802a086934b1cb13ac6ae02e8710c6f19d1113bd8b441a7e1d3.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/images/e6eb27e763b09802a086934b1cb13ac6ae02e8710c6f19d1113bd8b441a7e1d3.jpg)

### Tables

![0950801b5849cfb4d8569e74c0a73dd05a999557f360f2cf5931649016f9c832.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/0950801b5849cfb4d8569e74c0a73dd05a999557f360f2cf5931649016f9c832.jpg)

![195a9c9b5b6ba940c78b6fd816b7f8267e985484620537b2afe3e28336f3aba3.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/195a9c9b5b6ba940c78b6fd816b7f8267e985484620537b2afe3e28336f3aba3.jpg)

![231556c0765d9d09442ceac1be97aea6cd68b8f99d32878c00dc27e376ec0438.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/231556c0765d9d09442ceac1be97aea6cd68b8f99d32878c00dc27e376ec0438.jpg)

![45d139cbcd776910f5cdd7ac60fe296822b6367df3f001be81c66f7332301eb4.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/45d139cbcd776910f5cdd7ac60fe296822b6367df3f001be81c66f7332301eb4.jpg)

![62ff7f49af61f075cfaab67faee6e8c71ba31f5e7069f13707f0c9ed5ba40915.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/62ff7f49af61f075cfaab67faee6e8c71ba31f5e7069f13707f0c9ed5ba40915.jpg)

![68509c878569e0b04547328df16f0faafead77ff98fe97f3daa4c5e1abb38bb2.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/68509c878569e0b04547328df16f0faafead77ff98fe97f3daa4c5e1abb38bb2.jpg)

![8f352c84a82f8927875062fc68a834b393bb276fe3c2669d104d55192fa5994f.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/8f352c84a82f8927875062fc68a834b393bb276fe3c2669d104d55192fa5994f.jpg)

![98191592df697c3e0a3fdc3946a4a0173f743442fe5fd3a620c70e2aaec47769.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/98191592df697c3e0a3fdc3946a4a0173f743442fe5fd3a620c70e2aaec47769.jpg)

![b64852db76ca9446040198fd61aa7bffb2213a65c4ad71b5d7a35ce341d182c3.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/b64852db76ca9446040198fd61aa7bffb2213a65c4ad71b5d7a35ce341d182c3.jpg)

![c2717de2988a72cb1003445e363a4e353441de5215e114e50f1a9a3dfb3c4f64.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/c2717de2988a72cb1003445e363a4e353441de5215e114e50f1a9a3dfb3c4f64.jpg)

![eec1145eb7fba0c78d1b9959262577b0f90014640bf3be65d95e94b0fa0a07fa.jpg](../iclr_results/754_PFDiff_ Training-Free Acceleration of Diffusion Models Combining Past and Future Scores/tables/eec1145eb7fba0c78d1b9959262577b0f90014640bf3be65d95e94b0fa0a07fa.jpg)

## Learning to Communicate Through Implicit Communication Channels


### Images

![0f92da80ddef7a0276c0735f3948d8f6f6c87d9d61a866d56b435f71baa13eee.jpg](../iclr_results/755_Learning to Communicate Through Implicit Communication Channels/images/0f92da80ddef7a0276c0735f3948d8f6f6c87d9d61a866d56b435f71baa13eee.jpg)

![85254ab47c175dc1cefbe66c1c28dd9c5ff329d5e11e274c45ef210567fa4478.jpg](../iclr_results/755_Learning to Communicate Through Implicit Communication Channels/images/85254ab47c175dc1cefbe66c1c28dd9c5ff329d5e11e274c45ef210567fa4478.jpg)

![a2b5491efc6cb7bc8b2e4ef34d6635f91c2f13c8cb927779cbb9e3d0547ddd28.jpg](../iclr_results/755_Learning to Communicate Through Implicit Communication Channels/images/a2b5491efc6cb7bc8b2e4ef34d6635f91c2f13c8cb927779cbb9e3d0547ddd28.jpg)

![ca2e7b450d9a3b09300930c3b1c86642ae831e276bc865c1eac74b7b5704253b.jpg](../iclr_results/755_Learning to Communicate Through Implicit Communication Channels/images/ca2e7b450d9a3b09300930c3b1c86642ae831e276bc865c1eac74b7b5704253b.jpg)

## RESfM: Robust Deep Equivariant Structure from Motion


### Images

![468d10b8642177d0eba5fab384b359b18931c1bcca094fbd6471a99726b1c15d.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/images/468d10b8642177d0eba5fab384b359b18931c1bcca094fbd6471a99726b1c15d.jpg)

![7a5f327f04e47cd9e2ce1d543df0671067d9392fa02ffafe4598eafaf6949393.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/images/7a5f327f04e47cd9e2ce1d543df0671067d9392fa02ffafe4598eafaf6949393.jpg)

![ab8aab92c48ee483b3f8591239cd7a8be0dc05c23535f5adebd71b508c03ca40.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/images/ab8aab92c48ee483b3f8591239cd7a8be0dc05c23535f5adebd71b508c03ca40.jpg)

![ac1763bffaf3c28c988279a3a4fa131f752a609ae98edda8adcde4903978bc62.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/images/ac1763bffaf3c28c988279a3a4fa131f752a609ae98edda8adcde4903978bc62.jpg)

### Tables

![16e45ab00fe258ebffeb7814baaeffb3018b507d7de4afce70546740e83d0c02.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/16e45ab00fe258ebffeb7814baaeffb3018b507d7de4afce70546740e83d0c02.jpg)

![24414f21de5a2578f60df428e5a1cfc57fc9dd6ea5290dfd4c4a2616c8ae4d77.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/24414f21de5a2578f60df428e5a1cfc57fc9dd6ea5290dfd4c4a2616c8ae4d77.jpg)

![2b7ea39a958b51aff5b5fcc668a3e536212655c7045815310e64c5712ff20cea.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/2b7ea39a958b51aff5b5fcc668a3e536212655c7045815310e64c5712ff20cea.jpg)

![4a96067ddc41007dc73b5124308f608edfdcd9bf472e4b06cc8c79eba033e3e7.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/4a96067ddc41007dc73b5124308f608edfdcd9bf472e4b06cc8c79eba033e3e7.jpg)

![4d34dafbeb767d891f4f3f08dcb957d233c434585063bab7cad26c2902a263da.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/4d34dafbeb767d891f4f3f08dcb957d233c434585063bab7cad26c2902a263da.jpg)

![55c4f065f5eb79787691147cbac32dbafece40989c3deea7da846f65779b295e.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/55c4f065f5eb79787691147cbac32dbafece40989c3deea7da846f65779b295e.jpg)

![990b3e9f64495b485c9d9a4753e4f9fb5a225de93b3db461a6f1df130fec7f84.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/990b3e9f64495b485c9d9a4753e4f9fb5a225de93b3db461a6f1df130fec7f84.jpg)

![a58c79d09706ae2008fa03b541a0f7e80725ac4b9f67cf7dc8e535ac4ed5e7e0.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/a58c79d09706ae2008fa03b541a0f7e80725ac4b9f67cf7dc8e535ac4ed5e7e0.jpg)

![b8a90b057f2c061bffa769194b1f6dfc3b8c23a85c1ebfbda37477ee806709ea.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/b8a90b057f2c061bffa769194b1f6dfc3b8c23a85c1ebfbda37477ee806709ea.jpg)

![be5e59b7258744a40ac2a00b47488b685fa5c648ee81e157964a05a8e9908cdd.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/be5e59b7258744a40ac2a00b47488b685fa5c648ee81e157964a05a8e9908cdd.jpg)

![d042637f112dfb41b5d0d13250fe8111c886b4d27669337228db075750d6d52f.jpg](../iclr_results/756_RESfM_ Robust Deep Equivariant Structure from Motion/tables/d042637f112dfb41b5d0d13250fe8111c886b4d27669337228db075750d6d52f.jpg)

## Video In-context Learning: Autoregressive Transformers are Zero-Shot Video Imitators


### Images

![15c453128f6fbc0c9d57b14b1f1264b7467a6e37b8a7f770177c5bad9e98b3b5.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/15c453128f6fbc0c9d57b14b1f1264b7467a6e37b8a7f770177c5bad9e98b3b5.jpg)

![236d7361d4956c261a4a762e8cc3987cdb7fdc507c81bdbf62fe2608b06edcae.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/236d7361d4956c261a4a762e8cc3987cdb7fdc507c81bdbf62fe2608b06edcae.jpg)

![3d7d661789f76811ad2bd034a39d25a0b1ad01968de8211a39a2fa54cb1b46fa.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/3d7d661789f76811ad2bd034a39d25a0b1ad01968de8211a39a2fa54cb1b46fa.jpg)

![4107bba20fd9b0a86947a5107d0b447655aabb0c9d3a4793ea1fdca2d2015122.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/4107bba20fd9b0a86947a5107d0b447655aabb0c9d3a4793ea1fdca2d2015122.jpg)

![55f934bf8f33d679143033f91191c2d3c8cd908fb722087c67a9cb6db7ba3938.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/55f934bf8f33d679143033f91191c2d3c8cd908fb722087c67a9cb6db7ba3938.jpg)

![5922f18de6c0f21b02cd447881437c94519e08465bd96493a43b087912d9dec0.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/5922f18de6c0f21b02cd447881437c94519e08465bd96493a43b087912d9dec0.jpg)

![6affdab262db691601717b5262d806f4bf981fe120b2d365d9350e59c66e3fea.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/6affdab262db691601717b5262d806f4bf981fe120b2d365d9350e59c66e3fea.jpg)

![6fd88b859a461661c08a2a5d5842cf67961a6b5c360030820135b824cf5c630f.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/6fd88b859a461661c08a2a5d5842cf67961a6b5c360030820135b824cf5c630f.jpg)

![70bb9f37b650195a4c0c740ca2124c629485c6b8b202f25763428757f5bc0bed.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/70bb9f37b650195a4c0c740ca2124c629485c6b8b202f25763428757f5bc0bed.jpg)

![75b00101e0a8c12e3d339042dfd1d7114f9f841f6bca0217d687946ba71255de.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/75b00101e0a8c12e3d339042dfd1d7114f9f841f6bca0217d687946ba71255de.jpg)

![9a5995c024cc3483fc9fb43adf58b3044d1d4d75c269cfa11c61c2f9eaababc5.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/9a5995c024cc3483fc9fb43adf58b3044d1d4d75c269cfa11c61c2f9eaababc5.jpg)

![c7e3466ad85832c1d6f42bd4192769fddeec8483d43ab299c342fd6c32bef239.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/c7e3466ad85832c1d6f42bd4192769fddeec8483d43ab299c342fd6c32bef239.jpg)

![fea2006440b7057a21ca9e6832abe7cf9cb8b21da8ca6aabbe732f734a7a6aa1.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/images/fea2006440b7057a21ca9e6832abe7cf9cb8b21da8ca6aabbe732f734a7a6aa1.jpg)

### Tables

![2334d9d78af4138736237c42ec4f9d189bab89a3f46c54a5d4bfd369239df3cb.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/2334d9d78af4138736237c42ec4f9d189bab89a3f46c54a5d4bfd369239df3cb.jpg)

![274ac30fbe073d725b01558a7e2bd9b3de98877f7fc5e1ec374da5175d461246.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/274ac30fbe073d725b01558a7e2bd9b3de98877f7fc5e1ec374da5175d461246.jpg)

![6f20aac0483617dd12353f28a48517ba5a55d96aaa2fa2e4e43c4df83f812b96.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/6f20aac0483617dd12353f28a48517ba5a55d96aaa2fa2e4e43c4df83f812b96.jpg)

![7d6590d30b0eeff6013c2b9781b0568de82a073d62dd12b7b49228aea765956d.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/7d6590d30b0eeff6013c2b9781b0568de82a073d62dd12b7b49228aea765956d.jpg)

![a16c78cfc2feaf88ad2eb4f8222203bf2f38fda2258e9f70b0f3217deff6fbdf.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/a16c78cfc2feaf88ad2eb4f8222203bf2f38fda2258e9f70b0f3217deff6fbdf.jpg)

![a883d355edbfb807eb83a968c99df7c4cec6ac06be37938280eac7e7545e291a.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/a883d355edbfb807eb83a968c99df7c4cec6ac06be37938280eac7e7545e291a.jpg)

![b613d975296a07469b0f29d1d886cb8db44894d5e0d26c8f4410580c35f4bbd5.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/b613d975296a07469b0f29d1d886cb8db44894d5e0d26c8f4410580c35f4bbd5.jpg)

![c92f4784bccb8c00931ffc2bed5ed5987a3390780988f69a04af66523ccc85ba.jpg](../iclr_results/757_Video In-context Learning_ Autoregressive Transformers are Zero-Shot Video Imitators/tables/c92f4784bccb8c00931ffc2bed5ed5987a3390780988f69a04af66523ccc85ba.jpg)

## ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains


### Images

![0ed6506c17a81ddc29ea4a49e21d10169377f6619f2703d0d8eb7622db3f6cac.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/0ed6506c17a81ddc29ea4a49e21d10169377f6619f2703d0d8eb7622db3f6cac.jpg)

![14c555bb6bc74e95fa31f239cd2549b1179a61bdf508944f16a38f3cab1149c7.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/14c555bb6bc74e95fa31f239cd2549b1179a61bdf508944f16a38f3cab1149c7.jpg)

![1b7c127768f807085f620d9e7e926ff260eacabde74b727b4818f81c3f6c5670.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/1b7c127768f807085f620d9e7e926ff260eacabde74b727b4818f81c3f6c5670.jpg)

![1e4da4088e900d59307160e69766c1e160086059cc87f9641f538c62199dec5f.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/1e4da4088e900d59307160e69766c1e160086059cc87f9641f538c62199dec5f.jpg)

![212aca8d8fe10a4ed5e4e2d97ee41bb0a3d94f7a34de1fe66296fd41e00ab604.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/212aca8d8fe10a4ed5e4e2d97ee41bb0a3d94f7a34de1fe66296fd41e00ab604.jpg)

![24138b9e95c2d0946445edd47ea468cb53d01b6928147baebb4b82c1e9e2c199.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/24138b9e95c2d0946445edd47ea468cb53d01b6928147baebb4b82c1e9e2c199.jpg)

![38a664a86c8aed73cad2ebd3d2352b38d6625f44a56c20697f72edd05845d4e1.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/38a664a86c8aed73cad2ebd3d2352b38d6625f44a56c20697f72edd05845d4e1.jpg)

![38eb5c0266b5622d5e5d1544928a9e375f823d59e03d22fcc3cbe555f6b97e19.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/38eb5c0266b5622d5e5d1544928a9e375f823d59e03d22fcc3cbe555f6b97e19.jpg)

![675004ab034a489dad33c82bb00340c108ad4c53d11678b92c63418a10607edc.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/675004ab034a489dad33c82bb00340c108ad4c53d11678b92c63418a10607edc.jpg)

![7c967adcac4762ff97fe200c5b339f125357d2c298fb222c7153b60a0fe9a37b.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/7c967adcac4762ff97fe200c5b339f125357d2c298fb222c7153b60a0fe9a37b.jpg)

![83d3884d34166571a3d215e69464fefbcbae6a7bcf968acaf7794334ffb5a9a3.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/83d3884d34166571a3d215e69464fefbcbae6a7bcf968acaf7794334ffb5a9a3.jpg)

![9083d65ea22540bc285c56e039e73df1425fa183bc68d0daa8fd62f2c924c1f2.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/9083d65ea22540bc285c56e039e73df1425fa183bc68d0daa8fd62f2c924c1f2.jpg)

![9160c8f68514471d5bb77e62d8db80537de5c785c076bbf89b15e537cef23360.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/9160c8f68514471d5bb77e62d8db80537de5c785c076bbf89b15e537cef23360.jpg)

![9710c1be351542e71f79387f8b7c1a515eeb8a9a3485db0ea4a1cbd34e9963f0.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/9710c1be351542e71f79387f8b7c1a515eeb8a9a3485db0ea4a1cbd34e9963f0.jpg)

![a9c0681ce91a031b09c73561d561951d82cc8efd4de8ad48128cdd70955b5438.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/a9c0681ce91a031b09c73561d561951d82cc8efd4de8ad48128cdd70955b5438.jpg)

![bd9cd132b535d3fc95a01a72fda0fb31796d2443954fb8ddc87eea670116291b.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/bd9cd132b535d3fc95a01a72fda0fb31796d2443954fb8ddc87eea670116291b.jpg)

![ddadaf8a1c42cb6c436fed4b9374e2b44c79aca31c5f9c17332e3ad4e474ade8.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/ddadaf8a1c42cb6c436fed4b9374e2b44c79aca31c5f9c17332e3ad4e474ade8.jpg)

![ddf8302e8cd8a74b8e082326aac7db57c1471d22b54cc5d72ddb55b05cc7327f.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/ddf8302e8cd8a74b8e082326aac7db57c1471d22b54cc5d72ddb55b05cc7327f.jpg)

![fcbf61bf1c512831708ab77d49d15d964a50039477f41db02301f269e34d1386.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/images/fcbf61bf1c512831708ab77d49d15d964a50039477f41db02301f269e34d1386.jpg)

### Tables

![07b5e8e4a1ca8086d10fb9f96f1caa0ab0c3710733435ac035b858e1e3fa020a.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/07b5e8e4a1ca8086d10fb9f96f1caa0ab0c3710733435ac035b858e1e3fa020a.jpg)

![1ae2fe181a92b335ad54dfd0d044d85ddbac79f530de2677a875ebfcc590dbc1.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/1ae2fe181a92b335ad54dfd0d044d85ddbac79f530de2677a875ebfcc590dbc1.jpg)

![2928dc95548571a9c9494f14f47277e78bd7e7bbd324f6e1b1dc15fe1c3516d8.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/2928dc95548571a9c9494f14f47277e78bd7e7bbd324f6e1b1dc15fe1c3516d8.jpg)

![526f2b1d152dc10ba6544ec1d31b3969ae02c0687d467aaa1d199f1b07f4e9fb.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/526f2b1d152dc10ba6544ec1d31b3969ae02c0687d467aaa1d199f1b07f4e9fb.jpg)

![54ad1ab06f050ccbbf90ece494dc54bd267dad4498d444d84807ebae0c219955.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/54ad1ab06f050ccbbf90ece494dc54bd267dad4498d444d84807ebae0c219955.jpg)

![556700ec7da7b06c90fbb060aeccdf400dcc65d49824d7de1f05001e3364af96.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/556700ec7da7b06c90fbb060aeccdf400dcc65d49824d7de1f05001e3364af96.jpg)

![56580f0d8909e95bc8e10ce93d109942043170462bdc6ea362bf8136acfffe49.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/56580f0d8909e95bc8e10ce93d109942043170462bdc6ea362bf8136acfffe49.jpg)

![687e7b90a48cdd7755bdffb44147f8c8e082b843882a55d26bed2d81850b01f9.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/687e7b90a48cdd7755bdffb44147f8c8e082b843882a55d26bed2d81850b01f9.jpg)

![6dc354931efc9eb5cff68962dd6aea0469f34fd0a0aa9a44e6e7b60bc0cdd2e5.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/6dc354931efc9eb5cff68962dd6aea0469f34fd0a0aa9a44e6e7b60bc0cdd2e5.jpg)

![84db9440d03d78dacca3b494b3c7ea6d1bf45cfbc258c32c3a221b26da560531.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/84db9440d03d78dacca3b494b3c7ea6d1bf45cfbc258c32c3a221b26da560531.jpg)

![8967b2e0693ba8deb8b43d3314799c4dd6654aa154b92b748608e8a3997b344c.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/8967b2e0693ba8deb8b43d3314799c4dd6654aa154b92b748608e8a3997b344c.jpg)

![9bd6bb9ccb436574e1c25a3fd1239b7498bbfb035fec33c43e10e3dc54847c8e.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/9bd6bb9ccb436574e1c25a3fd1239b7498bbfb035fec33c43e10e3dc54847c8e.jpg)

![c6e213864d811fb5fb05fbb1b10e3ae24c6abc8e1101f0571bf55b95b6691532.jpg](../iclr_results/758_ChroKnowledge_ Unveiling Chronological Knowledge of Language Models in Multiple Domains/tables/c6e213864d811fb5fb05fbb1b10e3ae24c6abc8e1101f0571bf55b95b6691532.jpg)

## Aligning Visual Contrastive learning models via Preference Optimization


### Images

![14697993b6c6d7ab05d908a2390ab55025b51af28bd6e74344192ba089b2f8ae.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/14697993b6c6d7ab05d908a2390ab55025b51af28bd6e74344192ba089b2f8ae.jpg)

![1661567cc542878357b24f7b4beccb63388610f0c33c3a58dc0c591def60dffd.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/1661567cc542878357b24f7b4beccb63388610f0c33c3a58dc0c591def60dffd.jpg)

![1d605ad7a4164431f93cb9ed1f708265f91b535b7e13200e1e384685c15c0def.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/1d605ad7a4164431f93cb9ed1f708265f91b535b7e13200e1e384685c15c0def.jpg)

![2a6eec3d1b160f8e4554c47778f428347cac0eb98fa9570e0c60536fcfe5d63a.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/2a6eec3d1b160f8e4554c47778f428347cac0eb98fa9570e0c60536fcfe5d63a.jpg)

![31f2b75bc66877cac13fb64e333463d4db61c8174658d2a8f738d21b9d12ba7b.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/31f2b75bc66877cac13fb64e333463d4db61c8174658d2a8f738d21b9d12ba7b.jpg)

![3339f96fa5f21500162de283843179b157185ab50018d785e7ea4b6e22cb41ac.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/3339f96fa5f21500162de283843179b157185ab50018d785e7ea4b6e22cb41ac.jpg)

![539fda2401ce72cefd6000876eada900ad624a243fb528f599c8ff3ec669d09f.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/539fda2401ce72cefd6000876eada900ad624a243fb528f599c8ff3ec669d09f.jpg)

![6e58d62e8e65d096b44bf21f1e6fffa8b84ac2586b0abcd318b8aa741749f20c.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/6e58d62e8e65d096b44bf21f1e6fffa8b84ac2586b0abcd318b8aa741749f20c.jpg)

![75484e3491cb7a40871431d7d5a32f5847fd2a825910bfa58e52ccbda0da506c.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/75484e3491cb7a40871431d7d5a32f5847fd2a825910bfa58e52ccbda0da506c.jpg)

![99a33752671f7cf35837d57edd4c18c2014a50b949805bb24de951a1691d2ebc.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/99a33752671f7cf35837d57edd4c18c2014a50b949805bb24de951a1691d2ebc.jpg)

![bf50f6be6900329cebe34432d93aef74175961434d49603493eceb587a46b4e5.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/bf50f6be6900329cebe34432d93aef74175961434d49603493eceb587a46b4e5.jpg)

![c4ceefaaf3ff15ae26a96acd69206c7d30ed1c1a7805f41a1bf98528a60eeaa1.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/c4ceefaaf3ff15ae26a96acd69206c7d30ed1c1a7805f41a1bf98528a60eeaa1.jpg)

![ddafe7be5c87a217e6aef35bd3199f8b59073fed8f5934c3f4dec6b82086e24c.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/ddafe7be5c87a217e6aef35bd3199f8b59073fed8f5934c3f4dec6b82086e24c.jpg)

![e432dd05480a1a32dd84c14cbc797f4a89e07b7b41573d1aba4ce5d38c21e1bd.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/e432dd05480a1a32dd84c14cbc797f4a89e07b7b41573d1aba4ce5d38c21e1bd.jpg)

![e64ada06d404f29028cd5083a0fb31d43932ea58165587faa7b88be98d87b9dc.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/e64ada06d404f29028cd5083a0fb31d43932ea58165587faa7b88be98d87b9dc.jpg)

![e79591a015bcf9d2baa3d8b16023076c7dbae90a75b9d2fe6d771398b273ee40.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/e79591a015bcf9d2baa3d8b16023076c7dbae90a75b9d2fe6d771398b273ee40.jpg)

![e9aabdc42aebaaa987218d570fea294ee1fa1bba28ecf8c63672ae96423748b4.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/e9aabdc42aebaaa987218d570fea294ee1fa1bba28ecf8c63672ae96423748b4.jpg)

![efd0df50f1638ef1fc452f1a7cf55e23330b731c973fc84eacef5b98771e441b.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/efd0df50f1638ef1fc452f1a7cf55e23330b731c973fc84eacef5b98771e441b.jpg)

![f75a625ac39f503a9c9a70771cc0268b829e6ec5bc045cf6d461adfab2ff0d10.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/images/f75a625ac39f503a9c9a70771cc0268b829e6ec5bc045cf6d461adfab2ff0d10.jpg)

### Tables

![248397a47088893938fe28ab4734745379fabad27b6335b5bcc96741b71948d8.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/248397a47088893938fe28ab4734745379fabad27b6335b5bcc96741b71948d8.jpg)

![2c8f946949b8a383ef0893441ce9dfc53052ed9e40af643ebc927f020efd10fc.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/2c8f946949b8a383ef0893441ce9dfc53052ed9e40af643ebc927f020efd10fc.jpg)

![32da277c94731aab6f65f065c868df2391b351752ab9344e0cefaddae526e522.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/32da277c94731aab6f65f065c868df2391b351752ab9344e0cefaddae526e522.jpg)

![5fe703e95c1bced4b1b90a4b95def8f96650524a2ac254bdb061a85a7100e9c6.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/5fe703e95c1bced4b1b90a4b95def8f96650524a2ac254bdb061a85a7100e9c6.jpg)

![6fe3b23355209f84cecf12277e31e98d40e33a91bd9f0dd40e1d23329b089158.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/6fe3b23355209f84cecf12277e31e98d40e33a91bd9f0dd40e1d23329b089158.jpg)

![78c2c294db82c23d15166ca3543abe277f94e95e1bb1fc12e724f19a7f44352f.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/78c2c294db82c23d15166ca3543abe277f94e95e1bb1fc12e724f19a7f44352f.jpg)

![93727e7cb598d1a5d16f654857d9f3c69319d1d574ad0cbdc4b168b58887480d.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/93727e7cb598d1a5d16f654857d9f3c69319d1d574ad0cbdc4b168b58887480d.jpg)

![c566a462f44ad2ed05f126d094a3ddf337856b5597b553f6cc837994cf64987d.jpg](../iclr_results/759_Aligning Visual Contrastive learning models via Preference Optimization/tables/c566a462f44ad2ed05f126d094a3ddf337856b5597b553f6cc837994cf64987d.jpg)

## MGDA Converges under Generalized Smoothness, Provably


### Images

![2518313937a1ba885bfc9a437c5b80e23ffc118c79368b4669488f305adacb9c.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/images/2518313937a1ba885bfc9a437c5b80e23ffc118c79368b4669488f305adacb9c.jpg)

![caf7d2a6e016b1b6c345fded66d503a85be4ad33acc5ff8352d8ad72d4835e83.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/images/caf7d2a6e016b1b6c345fded66d503a85be4ad33acc5ff8352d8ad72d4835e83.jpg)

### Tables

![0a5685f4bf9064784ca9d534512e05c7062cfe96610629766673a28ce5471e2d.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/0a5685f4bf9064784ca9d534512e05c7062cfe96610629766673a28ce5471e2d.jpg)

![8954638f4751e4fe01dc7f4fd231ba7daf204e13af517a086ac4880f9194009f.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/8954638f4751e4fe01dc7f4fd231ba7daf204e13af517a086ac4880f9194009f.jpg)

![968b40b4d2c17e73cd5799f843d03623eaaba3a6aa8d48c4b43ab8d6d7b0c22b.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/968b40b4d2c17e73cd5799f843d03623eaaba3a6aa8d48c4b43ab8d6d7b0c22b.jpg)

![a741705457c9d04a9ba71f54a99024470bf0935bb7494108dcfb58daa9adf191.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/a741705457c9d04a9ba71f54a99024470bf0935bb7494108dcfb58daa9adf191.jpg)

![e1709c2093c39176a08bc8c67877d6da8b0799b321db2d84bc750174eee5d5b1.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/e1709c2093c39176a08bc8c67877d6da8b0799b321db2d84bc750174eee5d5b1.jpg)

![f2563e15e0668a8bc0fec52b611858bee46a88313e14e86dace54ef010362c09.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/f2563e15e0668a8bc0fec52b611858bee46a88313e14e86dace54ef010362c09.jpg)

![f39a4794ab0cd8eb0594d5e4606584ca978b0499adbe3becfce7da92a9745270.jpg](../iclr_results/760_MGDA Converges under Generalized Smoothness, Provably/tables/f39a4794ab0cd8eb0594d5e4606584ca978b0499adbe3becfce7da92a9745270.jpg)

## Making Text Embedders Few-Shot Learners


### Images

![015021d65f15b4801990ce7e59116ab73a4899039bb797010c1caf75f8046e60.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/images/015021d65f15b4801990ce7e59116ab73a4899039bb797010c1caf75f8046e60.jpg)

![4c3cf7b2d4191cc2afe1f58cfde62c5d5876426c2a5e330cadfba3a8e14f1be6.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/images/4c3cf7b2d4191cc2afe1f58cfde62c5d5876426c2a5e330cadfba3a8e14f1be6.jpg)

### Tables

![39c3b1a55d9d2cb5f29f06597b4bab580331524eae6131fb5f372601ddbb39e9.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/39c3b1a55d9d2cb5f29f06597b4bab580331524eae6131fb5f372601ddbb39e9.jpg)

![50e1504ae03345ada3ba807f29407c2a9ef5585aa6e9136d6edd2c39fc812434.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/50e1504ae03345ada3ba807f29407c2a9ef5585aa6e9136d6edd2c39fc812434.jpg)

![77c017d27ff2675e455394fe863fdf60a1b6292ddfbe397367be9aa0b4eedba5.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/77c017d27ff2675e455394fe863fdf60a1b6292ddfbe397367be9aa0b4eedba5.jpg)

![7df6d54314f93424ea3e1a85c26ed8f52ad78f2c3ca0dd745c16a18a94311619.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/7df6d54314f93424ea3e1a85c26ed8f52ad78f2c3ca0dd745c16a18a94311619.jpg)

![86d63a1971ba7d9c77799239aaa9ab345e5e00e2bb07a47117879fddb998ec6b.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/86d63a1971ba7d9c77799239aaa9ab345e5e00e2bb07a47117879fddb998ec6b.jpg)

![b79da8462bc67fd2ee224bbda2502f080f7e19b3a622e5c03d49ed6bc929d68a.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/b79da8462bc67fd2ee224bbda2502f080f7e19b3a622e5c03d49ed6bc929d68a.jpg)

![b8fcf66a59227edf32fa8abfce7f0d1d1c8b7c44b8bb2a8227f37a4043d91e7d.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/b8fcf66a59227edf32fa8abfce7f0d1d1c8b7c44b8bb2a8227f37a4043d91e7d.jpg)

![c62b7f779ceb0d6a1ac3b003b5bd95b2329fcd7ec2c6230aef87881ba04aa2e2.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/c62b7f779ceb0d6a1ac3b003b5bd95b2329fcd7ec2c6230aef87881ba04aa2e2.jpg)

![c87a1bb3c9476ce7eea7dacb01575c19e78e51b41e6c899d40f5dd66830c6fb4.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/c87a1bb3c9476ce7eea7dacb01575c19e78e51b41e6c899d40f5dd66830c6fb4.jpg)

![d680ff88c7e3d1c137311252f319d890861ff01885d2e1b941d1f306d2048a9f.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/d680ff88c7e3d1c137311252f319d890861ff01885d2e1b941d1f306d2048a9f.jpg)

![d69bbddaae8c807cf4291dee87b4dfc579311a315d70ebf0a5512fdda8b2ad39.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/d69bbddaae8c807cf4291dee87b4dfc579311a315d70ebf0a5512fdda8b2ad39.jpg)

![e48cb1406251e71ada82798838687c780a8659044ace241da6962e7646c0b6a7.jpg](../iclr_results/761_Making Text Embedders Few-Shot Learners/tables/e48cb1406251e71ada82798838687c780a8659044ace241da6962e7646c0b6a7.jpg)

## A Solvable Attention for Neural Scaling Laws


### Images

![237359108808c63ef3732821e88d4b28cf8a1e71cbef8352fc01cee142c93d73.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/237359108808c63ef3732821e88d4b28cf8a1e71cbef8352fc01cee142c93d73.jpg)

![3699c30de64c69d6f3b1205b641ef58ee3cc695cd56740a1d9b30daad8aee78e.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/3699c30de64c69d6f3b1205b641ef58ee3cc695cd56740a1d9b30daad8aee78e.jpg)

![42c24346b27a0ad08e16f185e0e31deabdb6cef1d4cdd480d76f3ae440c86aeb.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/42c24346b27a0ad08e16f185e0e31deabdb6cef1d4cdd480d76f3ae440c86aeb.jpg)

![60d6adbb8002d4db0d35999973a5ba9eb577b979852a9392cc2716760d9e2445.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/60d6adbb8002d4db0d35999973a5ba9eb577b979852a9392cc2716760d9e2445.jpg)

![64c18ca0db4deafcfc1c7e90fe764c4bb77c7c09ac4747b6d97599be18cd297a.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/64c18ca0db4deafcfc1c7e90fe764c4bb77c7c09ac4747b6d97599be18cd297a.jpg)

![7e143cebbb43b21d6f0655d3d0d2bf6b2cc0d3434d630787f0bb018a2df3231b.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/7e143cebbb43b21d6f0655d3d0d2bf6b2cc0d3434d630787f0bb018a2df3231b.jpg)

![8dbe4d90e42d50b10126820db75dbb2d08b30c42bf46b659221c8bdc04878d2d.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/8dbe4d90e42d50b10126820db75dbb2d08b30c42bf46b659221c8bdc04878d2d.jpg)

![8f63acadfd648f09fcaef2e54270d2d13cc9e84878f11106fd117a48d33855f8.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/8f63acadfd648f09fcaef2e54270d2d13cc9e84878f11106fd117a48d33855f8.jpg)

![b7383b67d2fe2a57a208f4011d1f104a7f0e154f240a589e6846ab3822d47487.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/b7383b67d2fe2a57a208f4011d1f104a7f0e154f240a589e6846ab3822d47487.jpg)

![fed873013d4955e5d7c694875a0c11ba7b2cc5b52e82480d686f70a77663eeb6.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/images/fed873013d4955e5d7c694875a0c11ba7b2cc5b52e82480d686f70a77663eeb6.jpg)

### Tables

![008823ec5e4d272b63b0a88c8a37c4ed9e307a298c0ccc6b8304e6608b0f89ea.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/tables/008823ec5e4d272b63b0a88c8a37c4ed9e307a298c0ccc6b8304e6608b0f89ea.jpg)

![09b95eef59b8e75b8ee3ff975433e861ed788b99c8eca01140be022a7cf3b5ee.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/tables/09b95eef59b8e75b8ee3ff975433e861ed788b99c8eca01140be022a7cf3b5ee.jpg)

![e029900099e14e34574662988aabdfb3d210834e25be0eee740ad66812582cec.jpg](../iclr_results/762_A Solvable Attention for Neural Scaling Laws/tables/e029900099e14e34574662988aabdfb3d210834e25be0eee740ad66812582cec.jpg)

## ST-GCond: Self-supervised and Transferable Graph Dataset Condensation


### Images

![0032c7e99dc1e25116694c6179e94f6db9e98ac31e24902f86c2e7b4bd13f7b3.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/0032c7e99dc1e25116694c6179e94f6db9e98ac31e24902f86c2e7b4bd13f7b3.jpg)

![3ba5673279aabebef0bff7197457b23164b94082fbf5eabb8a5e93eb85a0584d.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/3ba5673279aabebef0bff7197457b23164b94082fbf5eabb8a5e93eb85a0584d.jpg)

![4d29458c4435726a968ff8fb362584c7468f5fb4c5baa7b0dc3cfb066a327a26.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/4d29458c4435726a968ff8fb362584c7468f5fb4c5baa7b0dc3cfb066a327a26.jpg)

![51a25b9bda0b6f5551e9396d0f9611e3c53bd6f60584408109ed7f650a153bb5.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/51a25b9bda0b6f5551e9396d0f9611e3c53bd6f60584408109ed7f650a153bb5.jpg)

![b9e3677348e134d567d25e768e8d6404c31b23abbbb11b36f399ceb2cb6eb520.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/b9e3677348e134d567d25e768e8d6404c31b23abbbb11b36f399ceb2cb6eb520.jpg)

![d790a1f60cdd7d54c8c74023805b0552f64d9f31c38745a70ce585c3a98ca622.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/images/d790a1f60cdd7d54c8c74023805b0552f64d9f31c38745a70ce585c3a98ca622.jpg)

### Tables

![204f5e7e73fc35ea3643e89b4b5534c1cfe073dd209e74709479e7edb2a98b6c.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/204f5e7e73fc35ea3643e89b4b5534c1cfe073dd209e74709479e7edb2a98b6c.jpg)

![2399d18dd1296a2153a7c6ab9a7f0a2063dfde1f8347147f0924f06dc2f6720b.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/2399d18dd1296a2153a7c6ab9a7f0a2063dfde1f8347147f0924f06dc2f6720b.jpg)

![4c3f380ee69e3056747ee0bb8945dc2951b8f8de93da0e0d5d77cead61774f50.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/4c3f380ee69e3056747ee0bb8945dc2951b8f8de93da0e0d5d77cead61774f50.jpg)

![6e1757dea8b8c69d5dcea878969e02e61551a5247d5232d11702cc7b02de1eea.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/6e1757dea8b8c69d5dcea878969e02e61551a5247d5232d11702cc7b02de1eea.jpg)

![8746a2aae34a104aa2b0114a8a918a67bbb933608451629369f4d224878e8892.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/8746a2aae34a104aa2b0114a8a918a67bbb933608451629369f4d224878e8892.jpg)

![8cd63215f0cb796cbcf05e41cfdefc9fca96bec5488c880331670430b5879d05.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/8cd63215f0cb796cbcf05e41cfdefc9fca96bec5488c880331670430b5879d05.jpg)

![b771767f7391eff2882b264fafa19439233ff6180b5a756573a232d2d7e6ea09.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/b771767f7391eff2882b264fafa19439233ff6180b5a756573a232d2d7e6ea09.jpg)

![cc64184dce650be317a4cc34cbe47d49aff055af94d9d85ddb5c1289311cf7f0.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/cc64184dce650be317a4cc34cbe47d49aff055af94d9d85ddb5c1289311cf7f0.jpg)

![cdc4f203fa6ca51a4aed68070030cf0d9a87f9144aad497fbfe195b8000809af.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/cdc4f203fa6ca51a4aed68070030cf0d9a87f9144aad497fbfe195b8000809af.jpg)

![d2153fd6d9d4ebcb853583b13f432ed930094f99528dce6067637bba223617e7.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/d2153fd6d9d4ebcb853583b13f432ed930094f99528dce6067637bba223617e7.jpg)

![f07c4dbe98d946400ac57e2798c831de2ca303d4ce720d51bf0d692f5e2a67bd.jpg](../iclr_results/763_ST-GCond_ Self-supervised and Transferable Graph Dataset Condensation/tables/f07c4dbe98d946400ac57e2798c831de2ca303d4ce720d51bf0d692f5e2a67bd.jpg)

## Learning Successor Features with Distributed Hebbian Temporal Memory


### Images

![13df8f4fdfcc8741ebaa82c567e0726f5478c3c85cd27d28234cc562083e95d4.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/13df8f4fdfcc8741ebaa82c567e0726f5478c3c85cd27d28234cc562083e95d4.jpg)

![3f3fdef82b9696490230b5272b6c4ef010b0ecffda217522ea86160a1dc33fe9.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/3f3fdef82b9696490230b5272b6c4ef010b0ecffda217522ea86160a1dc33fe9.jpg)

![3f8429dd8aee005acd38cc888a5745d0e88f8fae6180178a2d0b53e066583b20.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/3f8429dd8aee005acd38cc888a5745d0e88f8fae6180178a2d0b53e066583b20.jpg)

![52d56b7ee9820d4bd9eee4fcf147f7be4076872b0843c2ba4ce2cbd801465ae1.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/52d56b7ee9820d4bd9eee4fcf147f7be4076872b0843c2ba4ce2cbd801465ae1.jpg)

![5b7c1fbd54526ca7c1b401ad3c45854ac1a9e9e128cf73836dad1d4ed881f7f2.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/5b7c1fbd54526ca7c1b401ad3c45854ac1a9e9e128cf73836dad1d4ed881f7f2.jpg)

![6949acd0c5c98eaaec9e89807d0d44eb34b42de7f71273ef2845106b86314a20.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/6949acd0c5c98eaaec9e89807d0d44eb34b42de7f71273ef2845106b86314a20.jpg)

![abf0ae8c24da54c587f14ddca5d10ba408590ef8ba3582863340cea62030ce34.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/abf0ae8c24da54c587f14ddca5d10ba408590ef8ba3582863340cea62030ce34.jpg)

![ad354e112efde29b319b1bed364bb735119124524aee0da7971b0d3213cc1e9b.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/ad354e112efde29b319b1bed364bb735119124524aee0da7971b0d3213cc1e9b.jpg)

![b088b613bb1163d0df13db670b6865275886ff9dcef957ce7c7272c8714f4369.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/b088b613bb1163d0df13db670b6865275886ff9dcef957ce7c7272c8714f4369.jpg)

![b90b1489b0d4db69ff9b8f71eaed7490b858293d8e31a685de90840fbcc36e6f.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/b90b1489b0d4db69ff9b8f71eaed7490b858293d8e31a685de90840fbcc36e6f.jpg)

![c473671ed3271d6dc8d0d53be10ce24ecbc617a7dc0ba35bb1a50e3663b0fc08.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/c473671ed3271d6dc8d0d53be10ce24ecbc617a7dc0ba35bb1a50e3663b0fc08.jpg)

![e7e4263f84ceb8e6530cfd1e6631ed911f1984f3fd79964a5603ac0c5e7d220d.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/images/e7e4263f84ceb8e6530cfd1e6631ed911f1984f3fd79964a5603ac0c5e7d220d.jpg)

### Tables

![62958dcf2b058d1e2420182b21e9c5649345ad38b65843ea74524730d3c0eff4.jpg](../iclr_results/764_Learning Successor Features with Distributed Hebbian Temporal Memory/tables/62958dcf2b058d1e2420182b21e9c5649345ad38b65843ea74524730d3c0eff4.jpg)

## Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct


### Images

![05b1aecb4c94d2588da45718828e1ac34e665ed8e25481981d005aff29540cee.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/05b1aecb4c94d2588da45718828e1ac34e665ed8e25481981d005aff29540cee.jpg)

![11e799fe29331603b41b1e5289b83d1e43860fee8f4c8a771873e2581137a7d5.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/11e799fe29331603b41b1e5289b83d1e43860fee8f4c8a771873e2581137a7d5.jpg)

![1c6175c9f650e497c7393a7e8697046a1f780c50c27745da7f6b7d31f8d386ac.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/1c6175c9f650e497c7393a7e8697046a1f780c50c27745da7f6b7d31f8d386ac.jpg)

![2bf26523c39fd1c59607947d773d5d403eb4b0469a8551e5ffab2f996a66f2d5.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/2bf26523c39fd1c59607947d773d5d403eb4b0469a8551e5ffab2f996a66f2d5.jpg)

![2dbd96ef69134927541d61cdb7d0ee5575d3a4bebd245718d6c98630eb5f94b1.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/2dbd96ef69134927541d61cdb7d0ee5575d3a4bebd245718d6c98630eb5f94b1.jpg)

![461d4aff65b12dd6911646a942f34c9c1c3e3241d53e360fa49c791e6db9bfa5.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/461d4aff65b12dd6911646a942f34c9c1c3e3241d53e360fa49c791e6db9bfa5.jpg)

![4df1bc6f2b1bd2372d2b856f0cb53c3c5cb83181a46e151175efcd67e57ac3cb.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/4df1bc6f2b1bd2372d2b856f0cb53c3c5cb83181a46e151175efcd67e57ac3cb.jpg)

![567799f8e7e6d9ce6e11319193ee91aea58e368fe672d7ccba10e8662afe82ee.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/567799f8e7e6d9ce6e11319193ee91aea58e368fe672d7ccba10e8662afe82ee.jpg)

![66e4f54ecbfaf7976d4ac5df13481568edb19d480e5db6da19a3c5e700699f8e.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/66e4f54ecbfaf7976d4ac5df13481568edb19d480e5db6da19a3c5e700699f8e.jpg)

![820869c866eb9a8fc448d2256b597afb71db5ec3045c42c6299c3daf7902aa76.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/820869c866eb9a8fc448d2256b597afb71db5ec3045c42c6299c3daf7902aa76.jpg)

![8d92543c4a681f2ef58d470ea7a552571fad157ee2dfdc072592399e0337d376.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/8d92543c4a681f2ef58d470ea7a552571fad157ee2dfdc072592399e0337d376.jpg)

![b28c04a26e0fb4364fb551b1980742cabd27b4ec9fe05e762d79235e6ec8c566.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/b28c04a26e0fb4364fb551b1980742cabd27b4ec9fe05e762d79235e6ec8c566.jpg)

![b952f059b89be574ab1105fa7fa8a234d110b889b0d85ad7bf99edc5bc879767.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/b952f059b89be574ab1105fa7fa8a234d110b889b0d85ad7bf99edc5bc879767.jpg)

![bfc7422cca5d819a90b32e88ac121b8911af79b6d85b53bfdafacde2d5b307c2.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/bfc7422cca5d819a90b32e88ac121b8911af79b6d85b53bfdafacde2d5b307c2.jpg)

![daa1627b42a271bfd97e593549a4cbf3ab61a98f6e05d21adb6c0fa899fdf9ec.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/daa1627b42a271bfd97e593549a4cbf3ab61a98f6e05d21adb6c0fa899fdf9ec.jpg)

![f5bf0e65426f7c91f3dd6fe7842b17779e52c6a40cb92677c9a624848d36983e.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/images/f5bf0e65426f7c91f3dd6fe7842b17779e52c6a40cb92677c9a624848d36983e.jpg)

### Tables

![4895ad655f215c6aeb0e8bba5cb51fd1b7625bb09d764a18d98d96e58c2cc647.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/4895ad655f215c6aeb0e8bba5cb51fd1b7625bb09d764a18d98d96e58c2cc647.jpg)

![524f26a9f8dc23d7c98ec757a220ec72ed430f6ec81ef52d6ff7af006fa85ba2.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/524f26a9f8dc23d7c98ec757a220ec72ed430f6ec81ef52d6ff7af006fa85ba2.jpg)

![878dc50ed3ee7dc7d5158d95dfa66f1e1a73ed117c42945193cd1c99e1b898a8.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/878dc50ed3ee7dc7d5158d95dfa66f1e1a73ed117c42945193cd1c99e1b898a8.jpg)

![a388e564c0bcb575a5c31c8de267f0853ff7cd09ff866820d64894355ce5226a.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/a388e564c0bcb575a5c31c8de267f0853ff7cd09ff866820d64894355ce5226a.jpg)

![afc51b7cc5a08cbea3fa0d22554b274fb69b2af6fe3f6c03015a1ed21bf86bc9.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/afc51b7cc5a08cbea3fa0d22554b274fb69b2af6fe3f6c03015a1ed21bf86bc9.jpg)

![b1841fbf94b9a6df5da11ea8c996ac4518ce022b4c0b70e0b32bdb506c8f2fc4.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/b1841fbf94b9a6df5da11ea8c996ac4518ce022b4c0b70e0b32bdb506c8f2fc4.jpg)

![ca767b94d52154dce123811cbc52d86369bb1e07379735cf11cbb57e18911a65.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/ca767b94d52154dce123811cbc52d86369bb1e07379735cf11cbb57e18911a65.jpg)

![cce0eb03d3b958c9697899a6ab8824a9d810a4c405d837af5c1218cbf540161f.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/cce0eb03d3b958c9697899a6ab8824a9d810a4c405d837af5c1218cbf540161f.jpg)

![fe964fc5139223da50bbab395501a617393ff2889747838a7c39788106147537.jpg](../iclr_results/765_Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct/tables/fe964fc5139223da50bbab395501a617393ff2889747838a7c39788106147537.jpg)

## When GNNs meet symmetry in ILPs: an orbit-based feature augmentation approach


### Images

![3e4705637b26d277aaba5f5bb835af0e7e7216d340807c0951ea734a7ec8cd25.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/images/3e4705637b26d277aaba5f5bb835af0e7e7216d340807c0951ea734a7ec8cd25.jpg)

![b926289b60ecd6ffa16c20c1bfba03e0b9cb5a746f4e93f758d6fce6f77afc22.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/images/b926289b60ecd6ffa16c20c1bfba03e0b9cb5a746f4e93f758d6fce6f77afc22.jpg)

### Tables

![0969a77facac5487890623924016c9a54e5516c32f182a37f7c03e8143fd2878.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/0969a77facac5487890623924016c9a54e5516c32f182a37f7c03e8143fd2878.jpg)

![b57c0e7b04f0c4d2180cde8c6a0aa660b18f9a0ff60be7a74bcddf9cf4ab7801.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/b57c0e7b04f0c4d2180cde8c6a0aa660b18f9a0ff60be7a74bcddf9cf4ab7801.jpg)

![c68af394559e4ed75c799b2ac25dd24b7cb93e1ed6aa814ab0cb88ee2384fe88.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/c68af394559e4ed75c799b2ac25dd24b7cb93e1ed6aa814ab0cb88ee2384fe88.jpg)

![cc88e331b50b49b63a5dccca96a7d876f8d741850711ba14143aa60f122b1756.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/cc88e331b50b49b63a5dccca96a7d876f8d741850711ba14143aa60f122b1756.jpg)

![e4aeaa7a0362a6e3ea0abeec389db08ec74d52612122fae81e902dc12e2e17d6.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/e4aeaa7a0362a6e3ea0abeec389db08ec74d52612122fae81e902dc12e2e17d6.jpg)

![ebb8ba3ac940b6c4f3f94626870cfbdbd67460fe2ecf48ef722f3c991cd3d019.jpg](../iclr_results/766_When GNNs meet symmetry in ILPs_ an orbit-based feature augmentation approach/tables/ebb8ba3ac940b6c4f3f94626870cfbdbd67460fe2ecf48ef722f3c991cd3d019.jpg)

## SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs


### Images

![1d843d023f9a2548154bde39ead2f4efc6ca21a999c76d262f8352fab4223561.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/images/1d843d023f9a2548154bde39ead2f4efc6ca21a999c76d262f8352fab4223561.jpg)

![787d9615bec499f7c393caf9db284ad122c9253eca3a4675d32d6fd26f763eab.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/images/787d9615bec499f7c393caf9db284ad122c9253eca3a4675d32d6fd26f763eab.jpg)

![98f715db99ddb048a371c896f47f01e19cd6f0228f4e557850ab3ff47fad48a5.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/images/98f715db99ddb048a371c896f47f01e19cd6f0228f4e557850ab3ff47fad48a5.jpg)

![a2c73b0a9c31fdff0b48ef04b0f51f70914c9e76e4ac44df40e73b88e45adc93.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/images/a2c73b0a9c31fdff0b48ef04b0f51f70914c9e76e4ac44df40e73b88e45adc93.jpg)

### Tables

![25f36efa1fb9290c68f70008f37bfe363e5aea856be47fbe2e8d3f29ace7c012.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/tables/25f36efa1fb9290c68f70008f37bfe363e5aea856be47fbe2e8d3f29ace7c012.jpg)

![3a16df29eaeaa8e7603b79ae69616f91b32aa1b8544a12f3af982732ff0458e5.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/tables/3a16df29eaeaa8e7603b79ae69616f91b32aa1b8544a12f3af982732ff0458e5.jpg)

![565bb40d9f99956d059d06a00422e09f2de433705724a1d82b7d856d2733bf25.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/tables/565bb40d9f99956d059d06a00422e09f2de433705724a1d82b7d856d2733bf25.jpg)

![7cfce37ec7a799a26c7772da50e3ae510b3a70c1ab7a62510a8c57c6accbe70a.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/tables/7cfce37ec7a799a26c7772da50e3ae510b3a70c1ab7a62510a8c57c6accbe70a.jpg)

![96008cc3888a7e87a484d5e792f34f061762ae4a89d6adf8a5ced1bc847a6235.jpg](../iclr_results/767_SINGER_ Stochastic Network Graph Evolving Operator for High Dimensional PDEs/tables/96008cc3888a7e87a484d5e792f34f061762ae4a89d6adf8a5ced1bc847a6235.jpg)

## FlashMask: Efficient and Rich Mask Extension of FlashAttention


### Images

![31cccf7d2230cd42370f22dbd369b91898c3c994cc6460ee9948e7a0c22a494e.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/31cccf7d2230cd42370f22dbd369b91898c3c994cc6460ee9948e7a0c22a494e.jpg)

![4ef40af9f7c1265db6bd948a5c00dbe0bec100595fb45152139e4f6ff038df6c.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/4ef40af9f7c1265db6bd948a5c00dbe0bec100595fb45152139e4f6ff038df6c.jpg)

![614690a4491cc98c45309762191597f22be621c6810403e0fa91f9a51039601a.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/614690a4491cc98c45309762191597f22be621c6810403e0fa91f9a51039601a.jpg)

![62738b7c0c7321853a0a744c0a1089b0fd95abca9ce7d89070375489fa86c490.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/62738b7c0c7321853a0a744c0a1089b0fd95abca9ce7d89070375489fa86c490.jpg)

![7e83e418506f61ae89827bb28501b3b558ebe74c6dbbbf79a080bb34bba60bd0.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/7e83e418506f61ae89827bb28501b3b558ebe74c6dbbbf79a080bb34bba60bd0.jpg)

![b4b051059d0db8b03437f832c5aea472c5b5a51f9751e0e2f131d3444ab13e5d.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/b4b051059d0db8b03437f832c5aea472c5b5a51f9751e0e2f131d3444ab13e5d.jpg)

![e2941dec5e2e61dc1d31aa82a869849ec5e0f8291a3bad3406e8cd1d9ff4dda2.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/e2941dec5e2e61dc1d31aa82a869849ec5e0f8291a3bad3406e8cd1d9ff4dda2.jpg)

![f96fa92b36492dfe1f2a5b1f776f29a2e2a3be941c96e4ef1fc11c0397136bc8.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/images/f96fa92b36492dfe1f2a5b1f776f29a2e2a3be941c96e4ef1fc11c0397136bc8.jpg)

### Tables

![1099d2b9f9ac35572003657443621b0cd53e3625150db758656810a716e56eef.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/1099d2b9f9ac35572003657443621b0cd53e3625150db758656810a716e56eef.jpg)

![15859f0b0fb61cc5bf0f0da0e2ed2869d8f699dce0056d662f77a41660721b1e.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/15859f0b0fb61cc5bf0f0da0e2ed2869d8f699dce0056d662f77a41660721b1e.jpg)

![1ed86b244c1c9f26c870d0166bb1026ab671c62f703536ea4ac79fae17e0707c.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/1ed86b244c1c9f26c870d0166bb1026ab671c62f703536ea4ac79fae17e0707c.jpg)

![22bce8bb3cfdf6186f2e78cadd3d9e7293f265711741a698f50426a9cf2a30ac.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/22bce8bb3cfdf6186f2e78cadd3d9e7293f265711741a698f50426a9cf2a30ac.jpg)

![2470b500d2d573b95e269591f1159297ab856d91ae922c78edd533842c513035.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/2470b500d2d573b95e269591f1159297ab856d91ae922c78edd533842c513035.jpg)

![261f593febc4930de82931dc521c2329d4b89785d23f184b011d0860ab3c82ee.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/261f593febc4930de82931dc521c2329d4b89785d23f184b011d0860ab3c82ee.jpg)

![4787ce4c70d439c1fcd0f37e1e7d5ed52aba135611a1ea85ade4849802bf3d64.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/4787ce4c70d439c1fcd0f37e1e7d5ed52aba135611a1ea85ade4849802bf3d64.jpg)

![64bdf619817a2cf9a15e27c92ff89ca39cb9752776a7e0bf7a44a0105e697642.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/64bdf619817a2cf9a15e27c92ff89ca39cb9752776a7e0bf7a44a0105e697642.jpg)

![6c0e93741ee8edacb4c5d4d100ba72f56a8a5926b1fc64f6471700f8f2179d47.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/6c0e93741ee8edacb4c5d4d100ba72f56a8a5926b1fc64f6471700f8f2179d47.jpg)

![7040d9c4df072002d477ad808b1232759f59c37a054f541d96ceeaeb88f313c6.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/7040d9c4df072002d477ad808b1232759f59c37a054f541d96ceeaeb88f313c6.jpg)

![74fafb82dacdcfb286d38686128ca033515fc66aab44070be105268bb4cac1d4.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/74fafb82dacdcfb286d38686128ca033515fc66aab44070be105268bb4cac1d4.jpg)

![8dd6c5947560fdfcfcb89d0abecef4472b2123484e8d0c122a83f84d61445a90.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/8dd6c5947560fdfcfcb89d0abecef4472b2123484e8d0c122a83f84d61445a90.jpg)

![c8ee45b397764a0d4222639ce95aef91df97f747e95fcd883922da4a885876e8.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/c8ee45b397764a0d4222639ce95aef91df97f747e95fcd883922da4a885876e8.jpg)

![cafe6dd23d0adc622992f0ec003025a90799d83e0a2d2bdcd78f179965242a23.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/cafe6dd23d0adc622992f0ec003025a90799d83e0a2d2bdcd78f179965242a23.jpg)

![de0a89cfa5d113185f419cd95b2b7468805331867f6690ea505b268844af6d24.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/de0a89cfa5d113185f419cd95b2b7468805331867f6690ea505b268844af6d24.jpg)

![de1aa46335530a69e4a902319a9dbeb0ae6daeb4434073cacc1b079b7d3afc31.jpg](../iclr_results/768_FlashMask_ Efficient and Rich Mask Extension of FlashAttention/tables/de1aa46335530a69e4a902319a9dbeb0ae6daeb4434073cacc1b079b7d3afc31.jpg)

## Towards Effective Evaluations and Comparisons for LLM Unlearning Methods


### Images

![1329f43d7a25504b999efbceefb6e7a261360e7b3ca6a6fcd577b39a1196587f.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/1329f43d7a25504b999efbceefb6e7a261360e7b3ca6a6fcd577b39a1196587f.jpg)

![1a71fd03038ebd6510c0f8dcc86010bb35f984a4ec59d992eaa6b6a055205a7b.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/1a71fd03038ebd6510c0f8dcc86010bb35f984a4ec59d992eaa6b6a055205a7b.jpg)

![20b71e10dee7baeff9e5663773ead09757efe7762d5af4294c6b16f51f5d39af.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/20b71e10dee7baeff9e5663773ead09757efe7762d5af4294c6b16f51f5d39af.jpg)

![79528dcf3fdca414a15b4b54f4c2fdb0930083735bd00c83306e29b3e7b4558f.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/79528dcf3fdca414a15b4b54f4c2fdb0930083735bd00c83306e29b3e7b4558f.jpg)

![a874f8e69407ed13e5e1712b8a398cfb1fac0803452c83fdb0df8a85906dad35.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/a874f8e69407ed13e5e1712b8a398cfb1fac0803452c83fdb0df8a85906dad35.jpg)

![aaaa975d2234868dcae9f924d312c297ffd95657fda45301138a4cac110df6b5.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/aaaa975d2234868dcae9f924d312c297ffd95657fda45301138a4cac110df6b5.jpg)

![e0c732b6e7f1767e10d845a30add2cd9ccd28d44f4c5b80f25b37280e306c0cd.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/images/e0c732b6e7f1767e10d845a30add2cd9ccd28d44f4c5b80f25b37280e306c0cd.jpg)

### Tables

![0d43ccc443336f360a1947de3144923ad1ac6aeff7ff8fc122fdf91b2f76ebe6.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/0d43ccc443336f360a1947de3144923ad1ac6aeff7ff8fc122fdf91b2f76ebe6.jpg)

![11f49d2783ffd0895081bf8e8949e41709219503c05da3d9290a65f49adff19d.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/11f49d2783ffd0895081bf8e8949e41709219503c05da3d9290a65f49adff19d.jpg)

![2b716c5d230591b73f05eb73c942cddd51077edda0fdd198d68f7edcc354e384.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/2b716c5d230591b73f05eb73c942cddd51077edda0fdd198d68f7edcc354e384.jpg)

![3c03678b32f8a9545c12f63b6903d2dcff8a105d1d7b8461c0b1f33c605942ce.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/3c03678b32f8a9545c12f63b6903d2dcff8a105d1d7b8461c0b1f33c605942ce.jpg)

![4727f65954ba14fac066767bc961e7bb6bbfc0ece63af9335d25b80e3a3a4787.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/4727f65954ba14fac066767bc961e7bb6bbfc0ece63af9335d25b80e3a3a4787.jpg)

![4c573ac71c0055e2f089577efcfea616030d7c5029f691ce488dd26776b0f02e.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/4c573ac71c0055e2f089577efcfea616030d7c5029f691ce488dd26776b0f02e.jpg)

![57e641472f108fe27dd501277715aaf0d4abf0097ea3e6c4f73e92447ee96cd3.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/57e641472f108fe27dd501277715aaf0d4abf0097ea3e6c4f73e92447ee96cd3.jpg)

![704d8a707100ca28cf9924ce18553e3516a95641b1e923a9a3cbe1e52b09ebce.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/704d8a707100ca28cf9924ce18553e3516a95641b1e923a9a3cbe1e52b09ebce.jpg)

![8fe0af8ad2ac565da4b8f05d1370146cd4ab363e87c5d9baf7100d8886343bf4.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/8fe0af8ad2ac565da4b8f05d1370146cd4ab363e87c5d9baf7100d8886343bf4.jpg)

![9a76f27a1fcb12f3437845ff6e515aa4032683ab6a2af2a34aabf4f8b34c51fb.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/9a76f27a1fcb12f3437845ff6e515aa4032683ab6a2af2a34aabf4f8b34c51fb.jpg)

![a07f416fc05f98575b72d6a6da3302ed17cb3a4c0eb28036754837e7c4e8984c.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/a07f416fc05f98575b72d6a6da3302ed17cb3a4c0eb28036754837e7c4e8984c.jpg)

![a50f33d42780b81d0dd237043eea0041843bf680663464c373037ada8b12de61.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/a50f33d42780b81d0dd237043eea0041843bf680663464c373037ada8b12de61.jpg)

![bbc34887acaf6b4933aee01fb7291b6c2086760b2dc28fc6e61e3a0ce58e24d5.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/bbc34887acaf6b4933aee01fb7291b6c2086760b2dc28fc6e61e3a0ce58e24d5.jpg)

![c06a549e044b907835e70599cec27abcb8b03afdf1b09e4e9317fe2b917f80e1.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/c06a549e044b907835e70599cec27abcb8b03afdf1b09e4e9317fe2b917f80e1.jpg)

![e25c11bf7ef615d81fda0fb428b2f883a19a25b61099186bcfdf35b1298dfbe7.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/e25c11bf7ef615d81fda0fb428b2f883a19a25b61099186bcfdf35b1298dfbe7.jpg)

![eeb75cf12390158cea6fa5769de9b8bb315b5844684478fd468d13f79aff26f8.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/eeb75cf12390158cea6fa5769de9b8bb315b5844684478fd468d13f79aff26f8.jpg)

![f6a63b2c7f24ae330fe066e934cd567064c4fdf0b295b39b54da0cc9834dd52b.jpg](../iclr_results/769_Towards Effective Evaluations and Comparisons for LLM Unlearning Methods/tables/f6a63b2c7f24ae330fe066e934cd567064c4fdf0b295b39b54da0cc9834dd52b.jpg)

## On Calibration of LLM-based Guard Models for Reliable Content Moderation


### Images

![265b9a53bbf9e085102559f68aa382ba4b0649e86a8dba98d8cdf89a9c603dd6.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/265b9a53bbf9e085102559f68aa382ba4b0649e86a8dba98d8cdf89a9c603dd6.jpg)

![664e190acf3d82247063f5405ef9a245d920a3682d6f261fa94658a44ef60609.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/664e190acf3d82247063f5405ef9a245d920a3682d6f261fa94658a44ef60609.jpg)

![85e93b86edd30787d6b5307c86264ae2ba0c85e45d1698b785b63f40bd81f05c.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/85e93b86edd30787d6b5307c86264ae2ba0c85e45d1698b785b63f40bd81f05c.jpg)

![933fc73f26e3701782c0721403a7f1092398a40998a7ef4cd8305d89e9df2551.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/933fc73f26e3701782c0721403a7f1092398a40998a7ef4cd8305d89e9df2551.jpg)

![94753e506e438f2409b2c01b7779f37d7337c828f9e5eaa375c2c7c7fcc6f833.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/94753e506e438f2409b2c01b7779f37d7337c828f9e5eaa375c2c7c7fcc6f833.jpg)

![b0242208f43e0e364a2612b89e8344c943f1c3d3b38b5e1a7f306daa87c640dc.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/b0242208f43e0e364a2612b89e8344c943f1c3d3b38b5e1a7f306daa87c640dc.jpg)

![b534adc513ce575ca2d9d487d703e9d90ebac2fb54a1baa872f35c24621d0d82.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/b534adc513ce575ca2d9d487d703e9d90ebac2fb54a1baa872f35c24621d0d82.jpg)

![d5da78025478978b835e861dc5951f546cdc02eb81f70718eb4ae6dd7fad1fc0.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/d5da78025478978b835e861dc5951f546cdc02eb81f70718eb4ae6dd7fad1fc0.jpg)

![f4bfc12b5325b914d02122db29e309918641366bbf11e8a9b298865b589ba226.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/images/f4bfc12b5325b914d02122db29e309918641366bbf11e8a9b298865b589ba226.jpg)

### Tables

![079b81a77cf5d95b1ecd01240c0f7fc8ff28b85ea6bf9c265dc2545a40f290b5.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/079b81a77cf5d95b1ecd01240c0f7fc8ff28b85ea6bf9c265dc2545a40f290b5.jpg)

![2f993274da59622fd179d0fb76d0cb80ebd73877800cd580291cbba6f7cf5473.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/2f993274da59622fd179d0fb76d0cb80ebd73877800cd580291cbba6f7cf5473.jpg)

![34b54f9014ce9aa0bfebcb10fdfbc9f251a8a5badb633a6c8934c99477cfaadb.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/34b54f9014ce9aa0bfebcb10fdfbc9f251a8a5badb633a6c8934c99477cfaadb.jpg)

![3c1b702a2c059fe27fd17e1c150cc6ce0049c968c9344f2eee1988dec7ee64aa.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/3c1b702a2c059fe27fd17e1c150cc6ce0049c968c9344f2eee1988dec7ee64aa.jpg)

![3f129f49b1dedfd78de1f6255d0e91e0d590a55b88d38eb090cb21a124f05021.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/3f129f49b1dedfd78de1f6255d0e91e0d590a55b88d38eb090cb21a124f05021.jpg)

![5d16793fd318f9842702812640410dc01c1689ee2ba337138fdf5322e10654a1.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/5d16793fd318f9842702812640410dc01c1689ee2ba337138fdf5322e10654a1.jpg)

![6c91969b3c1283e0f88f37610fd5c0c52a614022431f287c84a66a4fdc14f261.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/6c91969b3c1283e0f88f37610fd5c0c52a614022431f287c84a66a4fdc14f261.jpg)

![7529dcc8018b8b848594a92ed6f71bbc709768d2bf87bfd053697e5961abd21b.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/7529dcc8018b8b848594a92ed6f71bbc709768d2bf87bfd053697e5961abd21b.jpg)

![8047a9b2d589233808ac40dd2a1829aac632ba07dbbff75f1e6c51a39ad2c288.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/8047a9b2d589233808ac40dd2a1829aac632ba07dbbff75f1e6c51a39ad2c288.jpg)

![82f37816380897f24415e9947547929d15d98a6e036be5687ab6a26b14d4149b.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/82f37816380897f24415e9947547929d15d98a6e036be5687ab6a26b14d4149b.jpg)

![c45df9921ca3b827f45dcbf5155e28821811e6763ee65fb822bbcec37f2dc19f.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/c45df9921ca3b827f45dcbf5155e28821811e6763ee65fb822bbcec37f2dc19f.jpg)

![dc83a29214d2577bde37d024250669b87379bfe8940e3ce3cbcfa8da729ab093.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/dc83a29214d2577bde37d024250669b87379bfe8940e3ce3cbcfa8da729ab093.jpg)

![e6769d604195beeb9bda5ade5f5ef2943d910e5d8ba0e7b98cbcc37a0c6f6d79.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/e6769d604195beeb9bda5ade5f5ef2943d910e5d8ba0e7b98cbcc37a0c6f6d79.jpg)

![f7ad5c448076e116e42ab1254df2fd42c64532590034dd26d71e4d430285c3ac.jpg](../iclr_results/770_On Calibration of LLM-based Guard Models for Reliable Content Moderation/tables/f7ad5c448076e116e42ab1254df2fd42c64532590034dd26d71e4d430285c3ac.jpg)

## TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting


### Images

![1110f13a1e543a19be4e030673c0db302d4a908059221867358f6fe56460c85e.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/images/1110f13a1e543a19be4e030673c0db302d4a908059221867358f6fe56460c85e.jpg)

![60360e90e37b535a3c68ba4c2afa0235d4eda70752a48627a4173e1bc04fa0df.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/images/60360e90e37b535a3c68ba4c2afa0235d4eda70752a48627a4173e1bc04fa0df.jpg)

### Tables

![02d4a2dfff0b21242104ee7278a0b9538eebe13dac9c6756ea4ab5df15018a5e.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/02d4a2dfff0b21242104ee7278a0b9538eebe13dac9c6756ea4ab5df15018a5e.jpg)

![3f6934eb126c605bf08685d27c756935e193fab6ffa4578ed6948f4bbe620280.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/3f6934eb126c605bf08685d27c756935e193fab6ffa4578ed6948f4bbe620280.jpg)

![49f7b6e25c6954208e83e59d8877c43864a23370c15683d6153d79f0caf13da1.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/49f7b6e25c6954208e83e59d8877c43864a23370c15683d6153d79f0caf13da1.jpg)

![8b1a56231edecc182bad405b1d46a476b939ea09722cf78a7ee9a6b304091768.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/8b1a56231edecc182bad405b1d46a476b939ea09722cf78a7ee9a6b304091768.jpg)

![9c418d8718e79836503b38f53807d961bfe8642c4f1d5173870db6c403c3fa45.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/9c418d8718e79836503b38f53807d961bfe8642c4f1d5173870db6c403c3fa45.jpg)

![b9ad79176a6a7c2dc087c8fe90095cfff20b93dd6e530b5a1d17742c1d914295.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/b9ad79176a6a7c2dc087c8fe90095cfff20b93dd6e530b5a1d17742c1d914295.jpg)

![c10172aab94cc1141907225126501ca32af868a6dbb81a8cde7c5c6f216cbcc2.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/c10172aab94cc1141907225126501ca32af868a6dbb81a8cde7c5c6f216cbcc2.jpg)

![c592b4c41b71f86e2f788b98c2d4c867a452bb06053434bd4e58346dd4730cad.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/c592b4c41b71f86e2f788b98c2d4c867a452bb06053434bd4e58346dd4730cad.jpg)

![c86675a84cf96d4a76db7d6d8568e30c68f96f2741f8d769db7118017f7e8a40.jpg](../iclr_results/771_TimeKAN_ KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasti/tables/c86675a84cf96d4a76db7d6d8568e30c68f96f2741f8d769db7118017f7e8a40.jpg)

## SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance


### Images

![0c086e1ec562df2c674c2cd25f6caabcfc9b7f6eb8816f4ba776adc9d68d05ba.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/0c086e1ec562df2c674c2cd25f6caabcfc9b7f6eb8816f4ba776adc9d68d05ba.jpg)

![318d45b1e85c26fcdbe72202968ae1d8dce66fd7081b7fc4b2c21ac06bc07853.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/318d45b1e85c26fcdbe72202968ae1d8dce66fd7081b7fc4b2c21ac06bc07853.jpg)

![5535700ccd05d98f02200e8969399d00334ed05a275e90e29e9295048d676e0a.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/5535700ccd05d98f02200e8969399d00334ed05a275e90e29e9295048d676e0a.jpg)

![611cbb4799205578ae58bb2e023327d185466f7f7d9b002f86cdc3b6ebd81c8c.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/611cbb4799205578ae58bb2e023327d185466f7f7d9b002f86cdc3b6ebd81c8c.jpg)

![7a1c0168303334196cff8b28b0098b7461bea50f0f58ec9aca660324660183e6.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/7a1c0168303334196cff8b28b0098b7461bea50f0f58ec9aca660324660183e6.jpg)

![905df9140979e084818b7a9ca1b27c3fbab1d49731021cceebc1b8297c7e5e66.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/905df9140979e084818b7a9ca1b27c3fbab1d49731021cceebc1b8297c7e5e66.jpg)

![9ea1bb5feba91cb1fd6acf772e2b63bacb0eeb32323b63410b3ef6a685a7acff.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/9ea1bb5feba91cb1fd6acf772e2b63bacb0eeb32323b63410b3ef6a685a7acff.jpg)

![e419cdbaa0b57f483edcd928d22222e794dd7b6e148809ed30b237e08675fabf.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/e419cdbaa0b57f483edcd928d22222e794dd7b6e148809ed30b237e08675fabf.jpg)

![ee2f197aa7860a16276c37b6e2eca9b4b66689c86251b71bb68de665c0e0596c.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/images/ee2f197aa7860a16276c37b6e2eca9b4b66689c86251b71bb68de665c0e0596c.jpg)

### Tables

![18a2ecc578307cb19c99dcbbc52a77e68955d9afd0f8c48277e5cb07e6570a7c.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/18a2ecc578307cb19c99dcbbc52a77e68955d9afd0f8c48277e5cb07e6570a7c.jpg)

![2407ec358c5be1f94b5e2070a5db7eaf4031f6b7454391970db5dc81f49d4d2a.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/2407ec358c5be1f94b5e2070a5db7eaf4031f6b7454391970db5dc81f49d4d2a.jpg)

![282c88fbf5f34f906dccf203d5696beb0c13ab3e9d9ef45c7033160361dd6a60.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/282c88fbf5f34f906dccf203d5696beb0c13ab3e9d9ef45c7033160361dd6a60.jpg)

![2a9a49318f1620a3879965c73ebea9b84c887fb6fd84a95e98af1690c082a3ab.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/2a9a49318f1620a3879965c73ebea9b84c887fb6fd84a95e98af1690c082a3ab.jpg)

![359869b06e346acc858ed65833e277ccae7e4efd6807d67b9f22dd256efe53aa.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/359869b06e346acc858ed65833e277ccae7e4efd6807d67b9f22dd256efe53aa.jpg)

![38aaa19a276c131df7cbd48c43f0ce3301b08c42f70c39cf7e9501445d98a167.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/38aaa19a276c131df7cbd48c43f0ce3301b08c42f70c39cf7e9501445d98a167.jpg)

![43bbbfbd6d46d7d7ba3de51e1ce3765f6df71a2a3c6d08d4a112c997857e893a.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/43bbbfbd6d46d7d7ba3de51e1ce3765f6df71a2a3c6d08d4a112c997857e893a.jpg)

![52c30151566a7deae9d279170cda0cee9d17b0b70b18f47e06d386212ef86e34.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/52c30151566a7deae9d279170cda0cee9d17b0b70b18f47e06d386212ef86e34.jpg)

![5b334bedec06dafdd61b3ba7466f23965a52b107c024085da3c3e7e05b317134.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/5b334bedec06dafdd61b3ba7466f23965a52b107c024085da3c3e7e05b317134.jpg)

![64cf646139367be30dbfc016bf9eccfb6c231c4c9da2220047520be26d2ff278.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/64cf646139367be30dbfc016bf9eccfb6c231c4c9da2220047520be26d2ff278.jpg)

![71584284d8a31c233a4750952916d038e5cb4765f4563046ab968b673025bbb5.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/71584284d8a31c233a4750952916d038e5cb4765f4563046ab968b673025bbb5.jpg)

![987210fb1fe61e27f620365903932ee075b516a63f9f998d3cb6fe32bf1766e6.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/987210fb1fe61e27f620365903932ee075b516a63f9f998d3cb6fe32bf1766e6.jpg)

![9a684fac89eb7ad2166701cceb6d1723741045d79a4b306c940d4ecc00105b51.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/9a684fac89eb7ad2166701cceb6d1723741045d79a4b306c940d4ecc00105b51.jpg)

![a93acb0ba37628a8d5c40fb1d057816366f89f99736e9aee69d7d378f3ee7d43.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/a93acb0ba37628a8d5c40fb1d057816366f89f99736e9aee69d7d378f3ee7d43.jpg)

![c931655ea00ac6439cf924f004bb1f5bcd7faa4277822553164413b42d042ebc.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/c931655ea00ac6439cf924f004bb1f5bcd7faa4277822553164413b42d042ebc.jpg)

![e499b5b4188309799c2933e43d2bcf91c755e37840110f7792fef8a510ee3408.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/e499b5b4188309799c2933e43d2bcf91c755e37840110f7792fef8a510ee3408.jpg)

![f3d29736ae4f82fcc40b28511b9c0a7761ee9c45a966304913dc80f620613e7a.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/f3d29736ae4f82fcc40b28511b9c0a7761ee9c45a966304913dc80f620613e7a.jpg)

![fd24552cbca091aa8d77d0f855a57982fbbb18885b0c0eac808fa451fabbbb4b.jpg](../iclr_results/772_SBSC_ Step-by-Step Coding for Improving Mathematical Olympiad Performance/tables/fd24552cbca091aa8d77d0f855a57982fbbb18885b0c0eac808fa451fabbbb4b.jpg)

## NRGBoost: Energy-Based Generative Boosted Trees


### Images

![152bc7495ca6fc2ca4f1f67b3ccf89fe326aa1e348ff075f003a5ccc13ec4e49.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/152bc7495ca6fc2ca4f1f67b3ccf89fe326aa1e348ff075f003a5ccc13ec4e49.jpg)

![2ce327f68c48eb6a0f47decaaee5232e440796210c13eab99fa26930a8b1a0a8.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/2ce327f68c48eb6a0f47decaaee5232e440796210c13eab99fa26930a8b1a0a8.jpg)

![2dd3ca22b4f5a25c4ac98866b7c16e77cd53940acda3fedf394177abadb6a72a.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/2dd3ca22b4f5a25c4ac98866b7c16e77cd53940acda3fedf394177abadb6a72a.jpg)

![89fbee918506fec93b593b2d705dc09fc7cc0b9b75fdfecea84d08d4b57c4390.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/89fbee918506fec93b593b2d705dc09fc7cc0b9b75fdfecea84d08d4b57c4390.jpg)

![a40f613c441b56f651a9aeb9b6c8c7d51fdc85a83ff05735e19f143faf8d1c6f.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/a40f613c441b56f651a9aeb9b6c8c7d51fdc85a83ff05735e19f143faf8d1c6f.jpg)

![f972bc0467b73bcc89d04858bbef29a1ae258eb525faf205390818579ab33027.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/images/f972bc0467b73bcc89d04858bbef29a1ae258eb525faf205390818579ab33027.jpg)

### Tables

![0a25d154654b737d9505ec2f5f8288a387f26213caaf9687bb54d5edfc5d7f79.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/0a25d154654b737d9505ec2f5f8288a387f26213caaf9687bb54d5edfc5d7f79.jpg)

![1c3ff235874ac152d3b3284c09810edb8b4e33daae2e4f9165f922364e8ca7b3.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/1c3ff235874ac152d3b3284c09810edb8b4e33daae2e4f9165f922364e8ca7b3.jpg)

![240e6b7c403580ad6d84ddcf10711f191ed0a9ffe193c4310322dea6adc6614a.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/240e6b7c403580ad6d84ddcf10711f191ed0a9ffe193c4310322dea6adc6614a.jpg)

![2cfe4ca709603a5cc089c3fe435317bfe118e33c15ed76713770a81994002248.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/2cfe4ca709603a5cc089c3fe435317bfe118e33c15ed76713770a81994002248.jpg)

![33ba14d601fb4950c406766ac26e350e500a95e19b2e273ea79c973c6f34d9ec.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/33ba14d601fb4950c406766ac26e350e500a95e19b2e273ea79c973c6f34d9ec.jpg)

![577e71a4635bdb2128d7c83cf65b1c4de881d117dd49b49f25f699b0cb7491ac.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/577e71a4635bdb2128d7c83cf65b1c4de881d117dd49b49f25f699b0cb7491ac.jpg)

![5e91bcf6cb2480c9aedf130fb2dfc306a4df75416982bdb175eca90094bc17e5.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/5e91bcf6cb2480c9aedf130fb2dfc306a4df75416982bdb175eca90094bc17e5.jpg)

![9280793566ab8726ecc008763194145334de63ddd0473b8db050a2db8632cb1a.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/9280793566ab8726ecc008763194145334de63ddd0473b8db050a2db8632cb1a.jpg)

![9d78066d3bd7481902ea78e6236b0e3a5f169b7a5032d475736a45d17d20b998.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/9d78066d3bd7481902ea78e6236b0e3a5f169b7a5032d475736a45d17d20b998.jpg)

![a8f4b6fa7bc3a97659108cb2a96bf837f6603e075d2f816ba03dcb15df07e7e6.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/a8f4b6fa7bc3a97659108cb2a96bf837f6603e075d2f816ba03dcb15df07e7e6.jpg)

![bebf9721f19c77c522268e387f8ec2269c62b4720eae75bed9522da2f725a046.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/bebf9721f19c77c522268e387f8ec2269c62b4720eae75bed9522da2f725a046.jpg)

![d375fd3dc3a903fe65a5e58e518d9a7a9a4aeef3d114e02eb387153147f9eec5.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/d375fd3dc3a903fe65a5e58e518d9a7a9a4aeef3d114e02eb387153147f9eec5.jpg)

![dbdcdeb1627acb984ca86b4e83bd63f50436d541eee38c3dfbdb2a92da1c48f4.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/dbdcdeb1627acb984ca86b4e83bd63f50436d541eee38c3dfbdb2a92da1c48f4.jpg)

![e1da6470501c9d4a35d7e002a55c2b7c0bcd801c8b44fa6a3749dd03745fb642.jpg](../iclr_results/773_NRGBoost_ Energy-Based Generative Boosted Trees/tables/e1da6470501c9d4a35d7e002a55c2b7c0bcd801c8b44fa6a3749dd03745fb642.jpg)

## Process Reward Model with Q-value Rankings


### Images

![50d7b5767850b5b724bbbaaeace4856b75ef67c2d8abc48178817ac1cf2c9742.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/50d7b5767850b5b724bbbaaeace4856b75ef67c2d8abc48178817ac1cf2c9742.jpg)

![678e67627d9e4c351ef1ad065576a3e068736847dc43d2d0dc8d23bfb08d9ae1.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/678e67627d9e4c351ef1ad065576a3e068736847dc43d2d0dc8d23bfb08d9ae1.jpg)

![6b317e04ed8480af71eebcff6b984e46a9cccf35214f38c26f103a06f69f264c.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/6b317e04ed8480af71eebcff6b984e46a9cccf35214f38c26f103a06f69f264c.jpg)

![72614c78efddc74bc64352e5f14fe6f9dd6c3dbc78680df3f17658de9e785b54.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/72614c78efddc74bc64352e5f14fe6f9dd6c3dbc78680df3f17658de9e785b54.jpg)

![9bc256b115b1faf45208fb859338c2f5a867cd8fd745dfc92a7f377950dc21cd.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/9bc256b115b1faf45208fb859338c2f5a867cd8fd745dfc92a7f377950dc21cd.jpg)

![c358304add8e9fb7ce0fcbaca049154fe23fadd730c968316ecb4610c6485255.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/images/c358304add8e9fb7ce0fcbaca049154fe23fadd730c968316ecb4610c6485255.jpg)

### Tables

![300a1da6d797adf058662f2f395c5e8f89f8166258402aac49484ae8c0aa3955.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/300a1da6d797adf058662f2f395c5e8f89f8166258402aac49484ae8c0aa3955.jpg)

![32f12758170c444e2fd2d02c542a72efb5c84307c7f7f534fc5a88bf3774d35f.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/32f12758170c444e2fd2d02c542a72efb5c84307c7f7f534fc5a88bf3774d35f.jpg)

![333ba60ff0be598b4f059119f36bc509b9545bd5c88769433170036d50107b3c.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/333ba60ff0be598b4f059119f36bc509b9545bd5c88769433170036d50107b3c.jpg)

![35b3b8ee640fd9ef4e0ed4d25735421416d2071fbbb5339abafcbc16ab8ce685.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/35b3b8ee640fd9ef4e0ed4d25735421416d2071fbbb5339abafcbc16ab8ce685.jpg)

![4dc56153b1688f5454d97b9467b026bbef03c2d7ff2673eca7f834d9d97b2a83.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/4dc56153b1688f5454d97b9467b026bbef03c2d7ff2673eca7f834d9d97b2a83.jpg)

![685a6c07af50db044ce31366e23866c07b5143990cf6e768906b56b323fbb94c.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/685a6c07af50db044ce31366e23866c07b5143990cf6e768906b56b323fbb94c.jpg)

![6a896d3da8c8c95b5b7f23af4aceb10caeaf316420715f735413430d2b7bf842.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/6a896d3da8c8c95b5b7f23af4aceb10caeaf316420715f735413430d2b7bf842.jpg)

![6fdf559f6565aea4dbd8d3b7e4120761f64fc4f25133a54e7930b53cecea212d.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/6fdf559f6565aea4dbd8d3b7e4120761f64fc4f25133a54e7930b53cecea212d.jpg)

![af080cd2069ac941f0b897b3cb97b061535511e80656be184c1b4ee047343544.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/af080cd2069ac941f0b897b3cb97b061535511e80656be184c1b4ee047343544.jpg)

![ca7d2ad1680e28bbcf62cd0049ea929e8695404f78900a720b0184f254770161.jpg](../iclr_results/774_Process Reward Model with Q-value Rankings/tables/ca7d2ad1680e28bbcf62cd0049ea929e8695404f78900a720b0184f254770161.jpg)

## LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases


### Images

![37ba2c4aedcb68e741e7a46dc514e84b5f7a8da001a0498a821ecb79d53d775e.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/37ba2c4aedcb68e741e7a46dc514e84b5f7a8da001a0498a821ecb79d53d775e.jpg)

![7a28333d95637fed63db66141be65236f7a3467fed31630319caa6f0de3e167c.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/7a28333d95637fed63db66141be65236f7a3467fed31630319caa6f0de3e167c.jpg)

![89c3f0a657baa9a8a2fca28be01dadecd4e2c9e03504f756091a39b96068e4e9.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/89c3f0a657baa9a8a2fca28be01dadecd4e2c9e03504f756091a39b96068e4e9.jpg)

![a66386f9ac2bc0ff6c8cc3e4628ca69dd4b29a64308e684008b2f2c9dcdf081a.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/a66386f9ac2bc0ff6c8cc3e4628ca69dd4b29a64308e684008b2f2c9dcdf081a.jpg)

![b4b43844f37e27b23c21397df953fa82676da94fcb0999380ffaea3f9711e1a0.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/b4b43844f37e27b23c21397df953fa82676da94fcb0999380ffaea3f9711e1a0.jpg)

![c041f2ffb7c4c5307e3198783beb6a4422fe7cefaee537120fe0e4e9a75fed68.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/c041f2ffb7c4c5307e3198783beb6a4422fe7cefaee537120fe0e4e9a75fed68.jpg)

![e3c8613bb3e7fbb401abe6fffba9e8e6935edaa93dba6ca26f81e6c505158dac.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/images/e3c8613bb3e7fbb401abe6fffba9e8e6935edaa93dba6ca26f81e6c505158dac.jpg)

### Tables

![0cd3f405133be30d90cbcd5a4ae403fffee3d18497485490613581475b060bce.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/tables/0cd3f405133be30d90cbcd5a4ae403fffee3d18497485490613581475b060bce.jpg)

![76ae9dd4231c8c54434d0954059fa62941e5fd5f4c50ee7b8b12f9e9839e3498.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/tables/76ae9dd4231c8c54434d0954059fa62941e5fd5f4c50ee7b8b12f9e9839e3498.jpg)

![9ce22d13ea2257f1df12150090bb60f81e23a71ca6f375985bb02c043d619b08.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/tables/9ce22d13ea2257f1df12150090bb60f81e23a71ca6f375985bb02c043d619b08.jpg)

![a12f9fc9f57e20073125dcb11ee8cf14431ad605e3ee5620fb2114af1c604455.jpg](../iclr_results/775_LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases/tables/a12f9fc9f57e20073125dcb11ee8cf14431ad605e3ee5620fb2114af1c604455.jpg)

## Credit-based self organizing maps: training deep topographic networks with minimal performance degradation


### Images

![06ce6c8501fc7fa939a6f83712634eb3fb080c7a76752ef6299b19eb6ba31a67.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/06ce6c8501fc7fa939a6f83712634eb3fb080c7a76752ef6299b19eb6ba31a67.jpg)

![0d827ff6648908354c6c0c1683bf43a4ceb0edd764bce2e4c43dfcbfbc0239d0.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/0d827ff6648908354c6c0c1683bf43a4ceb0edd764bce2e4c43dfcbfbc0239d0.jpg)

![1d6c206dae9a398ecaa5720762f88a42086736d2246b36bf1b569786e9b8603a.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/1d6c206dae9a398ecaa5720762f88a42086736d2246b36bf1b569786e9b8603a.jpg)

![42d21b5f6e3fd88c68b0d15f9f61e140b1be5b963dfb02faefefc64dcd698ed0.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/42d21b5f6e3fd88c68b0d15f9f61e140b1be5b963dfb02faefefc64dcd698ed0.jpg)

![44269b8438b9e9559c03a745185d99d4f9c7b125ee7283c6a8c29dccdf1cb734.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/44269b8438b9e9559c03a745185d99d4f9c7b125ee7283c6a8c29dccdf1cb734.jpg)

![869c7a5d0efab6f7c2f7f06349dd440af52e2dbeffe3d9c9af14efb672696dd0.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/869c7a5d0efab6f7c2f7f06349dd440af52e2dbeffe3d9c9af14efb672696dd0.jpg)

![9514a0002d319646ad571dbd5a95edb6f91c519099d39bb4608e197a26fb51d9.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/9514a0002d319646ad571dbd5a95edb6f91c519099d39bb4608e197a26fb51d9.jpg)

![9a5a4422b162cd8d0544813f30bc50953dea58602f90a2324929597b01957c73.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/9a5a4422b162cd8d0544813f30bc50953dea58602f90a2324929597b01957c73.jpg)

![a28b8edf7c593c6a5dd2d1e219c3a79c6923bb4a306c615bf58a3ddfcecffb1c.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/a28b8edf7c593c6a5dd2d1e219c3a79c6923bb4a306c615bf58a3ddfcecffb1c.jpg)

![b381d075ad0296961c001ec789d05b2e44371aee4f4e46a60753f726e861a02d.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/b381d075ad0296961c001ec789d05b2e44371aee4f4e46a60753f726e861a02d.jpg)

![b5456eb093422d08cd1e4f7aa6d3535854407bb033022389cb69c58babc2a9cc.jpg](../iclr_results/776_Credit-based self organizing maps_ training deep topographic networks with minimal performance degra/images/b5456eb093422d08cd1e4f7aa6d3535854407bb033022389cb69c58babc2a9cc.jpg)

## Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions


### Images

![1852dca9cb434db2d8954f8f89f0472b9c6caa6f3ef0aa8e44293b38d0048aa9.jpg](../iclr_results/777_Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions/images/1852dca9cb434db2d8954f8f89f0472b9c6caa6f3ef0aa8e44293b38d0048aa9.jpg)

![61f054af4514c6ac9a880b9a9478f2d7947220d0329d6a3416179f1c98443173.jpg](../iclr_results/777_Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions/images/61f054af4514c6ac9a880b9a9478f2d7947220d0329d6a3416179f1c98443173.jpg)

![a81c25b417c7a32c3c0b0ea5d73b70e8afb0115fb6d854906fd9be017f294207.jpg](../iclr_results/777_Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions/images/a81c25b417c7a32c3c0b0ea5d73b70e8afb0115fb6d854906fd9be017f294207.jpg)

![be977319a21a038659b6f0cd2f314b333fec9685bf16376c6bbb744ec6b533b6.jpg](../iclr_results/777_Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions/images/be977319a21a038659b6f0cd2f314b333fec9685bf16376c6bbb744ec6b533b6.jpg)

![d546205df288f3a078152c7955e4abbc5165a285746226c6ab3f988c4d974cf8.jpg](../iclr_results/777_Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions/images/d546205df288f3a078152c7955e4abbc5165a285746226c6ab3f988c4d974cf8.jpg)

## LancBiO: Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace


### Images

![35092d731bc066f81da3c2760b61fcf78fa694badb632d04d0692e67abc60dea.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/35092d731bc066f81da3c2760b61fcf78fa694badb632d04d0692e67abc60dea.jpg)

![42c235f4b7f6ed2509686bc1c4f7714a60f5503ced91e549e3432ce551a43a6d.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/42c235f4b7f6ed2509686bc1c4f7714a60f5503ced91e549e3432ce551a43a6d.jpg)

![463b5bee8bc4bede2389151e0df3a391500cbc11b55799fbff14f5aecd7cf419.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/463b5bee8bc4bede2389151e0df3a391500cbc11b55799fbff14f5aecd7cf419.jpg)

![4a317c71f271e0026a809fc5bbac6e6b129d2ae77d2524450d0b11abd617b75c.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/4a317c71f271e0026a809fc5bbac6e6b129d2ae77d2524450d0b11abd617b75c.jpg)

![59cf5e1f493faa58e556bad3199214861b1b6051a884a12bc4da76e17dc93f46.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/59cf5e1f493faa58e556bad3199214861b1b6051a884a12bc4da76e17dc93f46.jpg)

![88d2c34b3cb9ac099139a1434cc7babe864bbdccbadfe7c4f0824a775bd24db2.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/88d2c34b3cb9ac099139a1434cc7babe864bbdccbadfe7c4f0824a775bd24db2.jpg)

![94541c485d479feb463e43e14fcf88f2a0b6503e3771efd93f0f73c0278686f6.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/94541c485d479feb463e43e14fcf88f2a0b6503e3771efd93f0f73c0278686f6.jpg)

![aeb4ba0e08814eda695a0f1c40989e68c968a044f02b4edbec0bd42c68ea9068.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/aeb4ba0e08814eda695a0f1c40989e68c968a044f02b4edbec0bd42c68ea9068.jpg)

![b1f709d92ebc696aecd4ce1e0f8c7dfb0dac1ecf80e738505cb5f71d8df21ca1.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/b1f709d92ebc696aecd4ce1e0f8c7dfb0dac1ecf80e738505cb5f71d8df21ca1.jpg)

![b970b69d9e25b3e55aa94f73f1954ff93f1b0aa0539477a147564d07eb38ac71.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/b970b69d9e25b3e55aa94f73f1954ff93f1b0aa0539477a147564d07eb38ac71.jpg)

![cb8a97fead6aed86d1b0a12c45dc5e3a7869273009247aa16bb994ddbd45abe9.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/cb8a97fead6aed86d1b0a12c45dc5e3a7869273009247aa16bb994ddbd45abe9.jpg)

![d4a39c2a4ee35719b0cb1997a22fd1c3c5666055b36ca5884ef357c0a956f91e.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/d4a39c2a4ee35719b0cb1997a22fd1c3c5666055b36ca5884ef357c0a956f91e.jpg)

![ffe1bc9191ce733dc8ca3ef2e868231e52e14beb4fbf992f3fcfb5c828bdc77f.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/images/ffe1bc9191ce733dc8ca3ef2e868231e52e14beb4fbf992f3fcfb5c828bdc77f.jpg)

### Tables

![a3c3814006169732c5615e0172b7f283c8d926c8fd7807c270446c2cd60a846e.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/tables/a3c3814006169732c5615e0172b7f283c8d926c8fd7807c270446c2cd60a846e.jpg)

![abcadd4784522573599084ec08b8b4b4604cecc400414a5d4c0ed38a39cf9835.jpg](../iclr_results/778_LancBiO_ Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace/tables/abcadd4784522573599084ec08b8b4b4604cecc400414a5d4c0ed38a39cf9835.jpg)

## Needle Threading: Can LLMs Follow Threads Through Near-Million-Scale Haystacks?


### Images

![01ef1b7cdb1581bdacfaeb60a9a516eef62ce39d63bdf5c4607adaf90844c524.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/01ef1b7cdb1581bdacfaeb60a9a516eef62ce39d63bdf5c4607adaf90844c524.jpg)

![2faaefbefbc3a281212baa141dd79898a5d8f96b246b19716e9f4f1a74b9b5c6.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/2faaefbefbc3a281212baa141dd79898a5d8f96b246b19716e9f4f1a74b9b5c6.jpg)

![34d8e9e684de2a0bf7010db3fb05b6d48c58902b4aabc289824f5d0333b409f6.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/34d8e9e684de2a0bf7010db3fb05b6d48c58902b4aabc289824f5d0333b409f6.jpg)

![40a95bae4fe7292ca540d96c6baab82325c8c3b5acc11baed4b7c53023b06fe2.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/40a95bae4fe7292ca540d96c6baab82325c8c3b5acc11baed4b7c53023b06fe2.jpg)

![4fde5c3ddb87159cdde0fa70d54aa6141d33acffcd04297f5888771429d2a700.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/4fde5c3ddb87159cdde0fa70d54aa6141d33acffcd04297f5888771429d2a700.jpg)

![578c912ce3a2e6b546c9b078551832ed1e5e92956883cecd551f83ff7cd08c2b.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/578c912ce3a2e6b546c9b078551832ed1e5e92956883cecd551f83ff7cd08c2b.jpg)

![58af6e8b49950379318e25844ea3e42c120aecdf2f16281a7ee759fc07df91b9.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/58af6e8b49950379318e25844ea3e42c120aecdf2f16281a7ee759fc07df91b9.jpg)

![75e67084d219476eaf7839234bee88c386ce9f0e5b76b42eecf8277e026211e1.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/75e67084d219476eaf7839234bee88c386ce9f0e5b76b42eecf8277e026211e1.jpg)

![76ec48927e2d89f9413cb2858b0cde0397a8fd5a4f832619f835c9bcead8e578.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/76ec48927e2d89f9413cb2858b0cde0397a8fd5a4f832619f835c9bcead8e578.jpg)

![8251feaeacd3a73a8ff6859b91c32322ca33eec9345dc1d2a041f9742e81bd31.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/8251feaeacd3a73a8ff6859b91c32322ca33eec9345dc1d2a041f9742e81bd31.jpg)

![8fe7b42b0d098654259e15a73ce202ae2aa393e58565bfe6ef236b490d94b596.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/8fe7b42b0d098654259e15a73ce202ae2aa393e58565bfe6ef236b490d94b596.jpg)

![a96203b50f9481f8883242d7170aff8906102ab3b3a326a18ad8f48f60363709.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/a96203b50f9481f8883242d7170aff8906102ab3b3a326a18ad8f48f60363709.jpg)

![aea12a4d61fbee31fe5969e7879c0611acf3cda6ce6ef2a1108fd01dd43cc056.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/aea12a4d61fbee31fe5969e7879c0611acf3cda6ce6ef2a1108fd01dd43cc056.jpg)

![cc2df71d72715d14325a2fb6ac0cb5c54d99256c6f221736003676287cf32ba8.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/cc2df71d72715d14325a2fb6ac0cb5c54d99256c6f221736003676287cf32ba8.jpg)

![cc58b47c1da7c881a6e3188c17e198ac9e462b6a17f250a635d9e0b20905e2de.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/cc58b47c1da7c881a6e3188c17e198ac9e462b6a17f250a635d9e0b20905e2de.jpg)

![d32bf12b88b2ba8ce7a8943ab645d64fa518c652a3afc38773ba2f549e56e0ad.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/d32bf12b88b2ba8ce7a8943ab645d64fa518c652a3afc38773ba2f549e56e0ad.jpg)

![dfcd56d61f54d103a45a8b84cab74b4107f946630c56f8ce20a959c162e9a683.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/dfcd56d61f54d103a45a8b84cab74b4107f946630c56f8ce20a959c162e9a683.jpg)

![e1c51ff95eaa948bd958350333d8e98540315353d839e52b69ae9b94ffb42317.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/e1c51ff95eaa948bd958350333d8e98540315353d839e52b69ae9b94ffb42317.jpg)

![f00ec33d06a6bdff5144f12f98ef83a760831be7945db7f10227db196e8e3c5e.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/images/f00ec33d06a6bdff5144f12f98ef83a760831be7945db7f10227db196e8e3c5e.jpg)

### Tables

![134bb3af6465e3f0d1ec1262b53d51fc31149b16204a61a7c03dcadf604f7d48.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/134bb3af6465e3f0d1ec1262b53d51fc31149b16204a61a7c03dcadf604f7d48.jpg)

![2dcc3e13733ca3a7eb13d33f44079e9f6b59acbd2389aba77c66c12e46c9dfe3.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/2dcc3e13733ca3a7eb13d33f44079e9f6b59acbd2389aba77c66c12e46c9dfe3.jpg)

![344d47e9086050c1bad3a358ff2058186372593151bedf3fd297d7ee1eaee1f2.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/344d47e9086050c1bad3a358ff2058186372593151bedf3fd297d7ee1eaee1f2.jpg)

![6dd6d3c564e117ab8aa246797979ce632a4ccc07b4386a85a3c47d2a4a173003.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/6dd6d3c564e117ab8aa246797979ce632a4ccc07b4386a85a3c47d2a4a173003.jpg)

![723ba140c2dd47de4ea1b989fa0d4f3e2cee833e61e5d5b8692cdf9d9b47e9be.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/723ba140c2dd47de4ea1b989fa0d4f3e2cee833e61e5d5b8692cdf9d9b47e9be.jpg)

![a47723cbd175fd65632a50d00797906d5feb024781dcc0f1dada667338998df3.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/a47723cbd175fd65632a50d00797906d5feb024781dcc0f1dada667338998df3.jpg)

![af1e853f642f03a4185d61bb4231833914ab95ec2e3c79fe4e4ab701b2192f39.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/af1e853f642f03a4185d61bb4231833914ab95ec2e3c79fe4e4ab701b2192f39.jpg)

![b11dfbf438c845e37f37a39c39c40d1748b2fc0e01f5178a997c23d33a9db408.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/b11dfbf438c845e37f37a39c39c40d1748b2fc0e01f5178a997c23d33a9db408.jpg)

![c6c9d2bfe824b974ff6a5254636ffe7c5c7686f84093f2f3f2eaa077182812c3.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/c6c9d2bfe824b974ff6a5254636ffe7c5c7686f84093f2f3f2eaa077182812c3.jpg)

![d1777f507f823000a96be517910d358888d7fff4d9330a240985aad163ba64c3.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/d1777f507f823000a96be517910d358888d7fff4d9330a240985aad163ba64c3.jpg)

![dcd695975f19c7d9f7bdeff7b456834f04a0c7a2b3812be821001f0d131ec52c.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/dcd695975f19c7d9f7bdeff7b456834f04a0c7a2b3812be821001f0d131ec52c.jpg)

![f46ddd200c3572fffc4bcdabb30cc96539219982934441d9100c25d96af364b1.jpg](../iclr_results/779_Needle Threading_ Can LLMs Follow Threads Through Near-Million-Scale Haystacks_/tables/f46ddd200c3572fffc4bcdabb30cc96539219982934441d9100c25d96af364b1.jpg)

## Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models


### Images

![073a055ad41f5dcac9f9281155352ffa3ed530956bda1ccce629bdeb4c333dc7.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/073a055ad41f5dcac9f9281155352ffa3ed530956bda1ccce629bdeb4c333dc7.jpg)

![088407e45ad5b232068250f4cbd9ab2e320e44521288b349d16285594b679470.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/088407e45ad5b232068250f4cbd9ab2e320e44521288b349d16285594b679470.jpg)

![0ad95e6b966bad8f906ceae00dd297e0733bd6fdae809f4202b0456fa35e38d3.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/0ad95e6b966bad8f906ceae00dd297e0733bd6fdae809f4202b0456fa35e38d3.jpg)

![11e3617552c5adaba6cd2aaeddb0fec95648bd7d09391d1631dd3ba2af3b6231.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/11e3617552c5adaba6cd2aaeddb0fec95648bd7d09391d1631dd3ba2af3b6231.jpg)

![1ba6a8a3ee8cd170317f19a1b6a7af30e242e27f30cc18e60415d96c9870712f.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/1ba6a8a3ee8cd170317f19a1b6a7af30e242e27f30cc18e60415d96c9870712f.jpg)

![241fb5f7cd22d3500c728aee5e9215d8992f2f9025b0bd5c74076afdf6e857f8.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/241fb5f7cd22d3500c728aee5e9215d8992f2f9025b0bd5c74076afdf6e857f8.jpg)

![3e35ef99da373c9e66bde25ebe1018332b5fb6d12cc17d2029daceab06f803e8.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/3e35ef99da373c9e66bde25ebe1018332b5fb6d12cc17d2029daceab06f803e8.jpg)

![3e93489bff30ec9021196f009fbc404f749a653a2959e8edfebe819089243fa8.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/3e93489bff30ec9021196f009fbc404f749a653a2959e8edfebe819089243fa8.jpg)

![5f1cd89a03d7aaa3fc3d200ae4362fa86f7dd04f8642ec0b27e81ad8d666becd.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/5f1cd89a03d7aaa3fc3d200ae4362fa86f7dd04f8642ec0b27e81ad8d666becd.jpg)

![6334cd5d6c47a3df30dae1886e4e3510f1f7a097f052f8e0899399746bf6a84e.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/6334cd5d6c47a3df30dae1886e4e3510f1f7a097f052f8e0899399746bf6a84e.jpg)

![677b31aa36a31994afe5c6b4e5e0693201577207723a6075b0461e8f0e93b995.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/677b31aa36a31994afe5c6b4e5e0693201577207723a6075b0461e8f0e93b995.jpg)

![69ad48344ae371460762bcb1eb2cad740f37703d6b1cc6dfeb736c3e3d2e2275.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/69ad48344ae371460762bcb1eb2cad740f37703d6b1cc6dfeb736c3e3d2e2275.jpg)

![6f84648c3c6c4cf476993e84a5ad69824b52c08d12d837bec58eb533b621ad4e.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/6f84648c3c6c4cf476993e84a5ad69824b52c08d12d837bec58eb533b621ad4e.jpg)

![76dc6cad7664865a457584d63898da13f53d11e922877ae08473bf61e227e06d.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/76dc6cad7664865a457584d63898da13f53d11e922877ae08473bf61e227e06d.jpg)

![82c3d8b6146574b69e6cdf466a1c85fa15251468f53a14e07a86e50d03263d58.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/82c3d8b6146574b69e6cdf466a1c85fa15251468f53a14e07a86e50d03263d58.jpg)

![8bd6650cda375e6244b9a7aa16aeb87ba3851e8ea95fdd5ae6271f11c25d7445.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/8bd6650cda375e6244b9a7aa16aeb87ba3851e8ea95fdd5ae6271f11c25d7445.jpg)

![9e2ba57290b4a2409708e80b8b9c05383b39bcc36d8e6828ac8711da712224b8.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/9e2ba57290b4a2409708e80b8b9c05383b39bcc36d8e6828ac8711da712224b8.jpg)

![b041ed92389a94350adfacdb16c0794e437d3ba8935d693d3fad02ebec708acb.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/b041ed92389a94350adfacdb16c0794e437d3ba8935d693d3fad02ebec708acb.jpg)

![b48c4a6892cc56e05715975f9ea6437a8dc77537cda282a2f61261b9e4cf537f.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/b48c4a6892cc56e05715975f9ea6437a8dc77537cda282a2f61261b9e4cf537f.jpg)

![b89124b5684f53bc042c279c1383918fa40ff1446ddbb0f4c23487d829f170dc.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/b89124b5684f53bc042c279c1383918fa40ff1446ddbb0f4c23487d829f170dc.jpg)

![cfefda7bddc8a54ad79b1d494d986791f951ea2b118fd18f999e91cc8542b593.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/cfefda7bddc8a54ad79b1d494d986791f951ea2b118fd18f999e91cc8542b593.jpg)

![d08b250e7920a0cd7cbc3e2ada30c54e906266009f97412f8c97b9f40769e778.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/d08b250e7920a0cd7cbc3e2ada30c54e906266009f97412f8c97b9f40769e778.jpg)

![d30c6462d6d26b43fab59b32ffddef915df6dd12dff27a571664fcb461bb4a24.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/d30c6462d6d26b43fab59b32ffddef915df6dd12dff27a571664fcb461bb4a24.jpg)

![d61189c24fc38e729ae3dae201f91a503e71639152be62f25f16c7c16dd196cc.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/d61189c24fc38e729ae3dae201f91a503e71639152be62f25f16c7c16dd196cc.jpg)

![d7aa23e3fe5ab43eccc770675921fa27a790c69d5b2cb06adb4569a0911c6179.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/d7aa23e3fe5ab43eccc770675921fa27a790c69d5b2cb06adb4569a0911c6179.jpg)

![f9d0230ca6f4735beeddfb27f60e166fe34ccaa42c1ecf9708ede32e8e463b65.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/images/f9d0230ca6f4735beeddfb27f60e166fe34ccaa42c1ecf9708ede32e8e463b65.jpg)

### Tables

![10ae7cf9af9e1a2a79263f237be6081afacc775849c7dfebfd233f08ec615add.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/10ae7cf9af9e1a2a79263f237be6081afacc775849c7dfebfd233f08ec615add.jpg)

![587eb53bd0d78ba512fbc5b019758dd8a08f5af57bf5dc29addd89acdfde5aac.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/587eb53bd0d78ba512fbc5b019758dd8a08f5af57bf5dc29addd89acdfde5aac.jpg)

![6755105c7d0986c2dc306dc92766bb4510999bb474416c867e317d598c2832a0.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/6755105c7d0986c2dc306dc92766bb4510999bb474416c867e317d598c2832a0.jpg)

![7c6fedb6ddf9947dd1ae149e0c5dcdd2b1f7fe4a7b9ef1125f877d5afe3910c5.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/7c6fedb6ddf9947dd1ae149e0c5dcdd2b1f7fe4a7b9ef1125f877d5afe3910c5.jpg)

![ba6cc8edc1b34cdf9079fc7ab321ac281c47a8956540df7ea850bbacaeb51558.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/ba6cc8edc1b34cdf9079fc7ab321ac281c47a8956540df7ea850bbacaeb51558.jpg)

![bf9df1d84eddf6190e90b1d0ff730d37489066f78ae3fcb246013fc179b3e84b.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/bf9df1d84eddf6190e90b1d0ff730d37489066f78ae3fcb246013fc179b3e84b.jpg)

![fa6dd7dd5bb18ff68ee462c7b1d724ae216cf3a850c11e1b752035784aee0eda.jpg](../iclr_results/780_Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models/tables/fa6dd7dd5bb18ff68ee462c7b1d724ae216cf3a850c11e1b752035784aee0eda.jpg)

## Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrieval


### Images

![0c1b7da6f042d0f0b026507a1b814771068550b139b53acea0a809bbc3464a54.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/0c1b7da6f042d0f0b026507a1b814771068550b139b53acea0a809bbc3464a54.jpg)

![35d2859f6c9d91cca6445d210d7e7da158ab6af3e7261649ce195af3719c5e73.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/35d2859f6c9d91cca6445d210d7e7da158ab6af3e7261649ce195af3719c5e73.jpg)

![4298cc9118e6e9ca89ae2f621c364aff9b10093846b9c487d8f5e73f5d56573b.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/4298cc9118e6e9ca89ae2f621c364aff9b10093846b9c487d8f5e73f5d56573b.jpg)

![7dd3e66646bde0b23aa288509d9fd67d4c29e50cb1542150c13172aeb721b31f.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/7dd3e66646bde0b23aa288509d9fd67d4c29e50cb1542150c13172aeb721b31f.jpg)

![85a6ca1f5a5a8e0858110a548fb0e449cafd2c3fc7ded1ee3903c5672919d07c.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/85a6ca1f5a5a8e0858110a548fb0e449cafd2c3fc7ded1ee3903c5672919d07c.jpg)

![866ad7b72ad7f0e632f860bd3288b85ad7bf081de4e19bba03079369578918db.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/866ad7b72ad7f0e632f860bd3288b85ad7bf081de4e19bba03079369578918db.jpg)

![9114b28976ac0d4efcb249501c64d1dd05dabaeff8731f96fd0f1209e7803a75.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/9114b28976ac0d4efcb249501c64d1dd05dabaeff8731f96fd0f1209e7803a75.jpg)

![941397913504fa7fedc97e28b6a63075b4d0a1fe272bad7ac33cc9d40ccb5989.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/941397913504fa7fedc97e28b6a63075b4d0a1fe272bad7ac33cc9d40ccb5989.jpg)

![ac3ef6af3cd9e6156dc3a8270f8338b32a1f4c9bd1c73772e9cb0dcca5fb900c.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/ac3ef6af3cd9e6156dc3a8270f8338b32a1f4c9bd1c73772e9cb0dcca5fb900c.jpg)

![ae7d306ac5c5e6946b463f3899dfc1be2472b2f113c21f70186dcb63584df7ee.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/ae7d306ac5c5e6946b463f3899dfc1be2472b2f113c21f70186dcb63584df7ee.jpg)

![c70586753381e70b1a9307ab2cc256032006109c4780ec87fe5d280df06f3f35.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/c70586753381e70b1a9307ab2cc256032006109c4780ec87fe5d280df06f3f35.jpg)

![f3f15500339bfddaab8ecdb59e906a744c175d08d5ee5a356e83b660183909f7.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/f3f15500339bfddaab8ecdb59e906a744c175d08d5ee5a356e83b660183909f7.jpg)

![fd5bdc3124b9295c802e89e9b64180b8f4871fe62165e645aa04e99986504300.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/fd5bdc3124b9295c802e89e9b64180b8f4871fe62165e645aa04e99986504300.jpg)

![ffa892761d60eb3a7e1bfe485f079ab2eac82b51b28a8ddf7182c1707c20391f.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/images/ffa892761d60eb3a7e1bfe485f079ab2eac82b51b28a8ddf7182c1707c20391f.jpg)

### Tables

![1428b703ef42676c86d45da81eefa283634607c06f414367313e8ccce48d24f1.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/1428b703ef42676c86d45da81eefa283634607c06f414367313e8ccce48d24f1.jpg)

![25fb9464db6f0bc53bf2c15147cce412fee8bff59f40641d37a05e346a893e3f.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/25fb9464db6f0bc53bf2c15147cce412fee8bff59f40641d37a05e346a893e3f.jpg)

![261c9c1645916f5e6274c217c77fef85885c4aac2539dac065e6197264c080b9.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/261c9c1645916f5e6274c217c77fef85885c4aac2539dac065e6197264c080b9.jpg)

![2ca1ee6033c070ccb6e24c5d46d247ffc47216f8cdf52393c1c9e686c07aed71.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/2ca1ee6033c070ccb6e24c5d46d247ffc47216f8cdf52393c1c9e686c07aed71.jpg)

![498f93db6f1f5a484a66cacd60b399b4d60b6600e1f84887e91ec114706c7c37.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/498f93db6f1f5a484a66cacd60b399b4d60b6600e1f84887e91ec114706c7c37.jpg)

![626a24b9efbbc46ebcf72ae62a2f71585c80649eb13721b165e49a760e14d64f.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/626a24b9efbbc46ebcf72ae62a2f71585c80649eb13721b165e49a760e14d64f.jpg)

![7ead9572e6d22e8cea2535a21817bf0b2039d38beca32a6bb38cc7ddf166e4c1.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/7ead9572e6d22e8cea2535a21817bf0b2039d38beca32a6bb38cc7ddf166e4c1.jpg)

![83734ff24e182bc78d192f20abc4c447204227bacdfffb9e849a3e837ddc7d4a.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/83734ff24e182bc78d192f20abc4c447204227bacdfffb9e849a3e837ddc7d4a.jpg)

![b049e182c3782e407df20985641ad9e19639879ba7510af92b01b3747cd77356.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/b049e182c3782e407df20985641ad9e19639879ba7510af92b01b3747cd77356.jpg)

![b54a235a3ab14d2e5ef13fb9cf87bbaaae0e818b52fece00b7aef503994c80a9.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/b54a235a3ab14d2e5ef13fb9cf87bbaaae0e818b52fece00b7aef503994c80a9.jpg)

![b9e74c53fc43c9f6b88f95f005f35b6e220ed9f961941d967c891a3e7b43866b.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/b9e74c53fc43c9f6b88f95f005f35b6e220ed9f961941d967c891a3e7b43866b.jpg)

![bdba0939275c3e777565738bb8988ddb2240368184cee706a6bb9f7b90440551.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/bdba0939275c3e777565738bb8988ddb2240368184cee706a6bb9f7b90440551.jpg)

![c1a3a401ca68f30d8e4f6ecf423b072d810079057337462430382e422adcbcb1.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/c1a3a401ca68f30d8e4f6ecf423b072d810079057337462430382e422adcbcb1.jpg)

![e3dd18c5d8a066a8519224e5e119145280a941f5d79bcf3163b2e913cdb5ca39.jpg](../iclr_results/781_Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrie/tables/e3dd18c5d8a066a8519224e5e119145280a941f5d79bcf3163b2e913cdb5ca39.jpg)

## SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation


### Images

![2776a05898e338c8eec46ef780d9cd024bc7a77e4cc9d60a55c43eb1c81cebde.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/2776a05898e338c8eec46ef780d9cd024bc7a77e4cc9d60a55c43eb1c81cebde.jpg)

![54aa12ca721f301e6858045f6f56282dc8103b3a3cfc974611505088b15771d4.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/54aa12ca721f301e6858045f6f56282dc8103b3a3cfc974611505088b15771d4.jpg)

![54c4d2e4be7d483bf89d927488621de177d0cda661b2361d7dc8120398fc4d40.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/54c4d2e4be7d483bf89d927488621de177d0cda661b2361d7dc8120398fc4d40.jpg)

![8187d895b71dbc03d32afae50f44f1584c06575614614ccdc588e44a85e9927f.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/8187d895b71dbc03d32afae50f44f1584c06575614614ccdc588e44a85e9927f.jpg)

![835365aa1ae1dc3d3b04857d0e8458e9edf717d87c416f0aa0fd855f25998c11.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/835365aa1ae1dc3d3b04857d0e8458e9edf717d87c416f0aa0fd855f25998c11.jpg)

![bb859c5bf4580f26373bbeb5fb700ff67810a906ca9a302cfaa6e6ad7b874ce5.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/bb859c5bf4580f26373bbeb5fb700ff67810a906ca9a302cfaa6e6ad7b874ce5.jpg)

![c3a5d32c8fd8de9370abb1563bfc48ebf078faf06a8b83a24ca02a8fa99f7f8d.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/images/c3a5d32c8fd8de9370abb1563bfc48ebf078faf06a8b83a24ca02a8fa99f7f8d.jpg)

### Tables

![11f9c7b4968944a505d90e50b51c68eb69f28c1ab8f2e616241182f271a1b1f5.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/tables/11f9c7b4968944a505d90e50b51c68eb69f28c1ab8f2e616241182f271a1b1f5.jpg)

![ac084644cb10c4b37f137cefa908fed315116d308b2ff04d2904171490c4702d.jpg](../iclr_results/782_SaRA_ High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation/tables/ac084644cb10c4b37f137cefa908fed315116d308b2ff04d2904171490c4702d.jpg)

## Tree of Attributes Prompt Learning for Vision-Language Models


### Images

![6bccf921415fe7e6d97183195f0f4a36a2a65dc9c8cd208e31b815b1f995129e.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/images/6bccf921415fe7e6d97183195f0f4a36a2a65dc9c8cd208e31b815b1f995129e.jpg)

![853853fb1f66d919acff2288450bc3d7304bec6f1450696f440a31caa2d41a4c.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/images/853853fb1f66d919acff2288450bc3d7304bec6f1450696f440a31caa2d41a4c.jpg)

![adae1d51d308899b8a5a50f72794e2290ba29b18a48227c24ff63d2486e8775e.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/images/adae1d51d308899b8a5a50f72794e2290ba29b18a48227c24ff63d2486e8775e.jpg)

![cfbc1d08b974758c1df32d8b176167e15a1cc77f94f5b9a1743c694d0e701b8d.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/images/cfbc1d08b974758c1df32d8b176167e15a1cc77f94f5b9a1743c694d0e701b8d.jpg)

### Tables

![0ead67aab4e518f872def072dc1f6de79d7e641c9032266e992531c3ad1070ef.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/0ead67aab4e518f872def072dc1f6de79d7e641c9032266e992531c3ad1070ef.jpg)

![442306d2685b8f04bdd1db20cafdd283f5744c7ec42ba2be15a7ed2c29199b6a.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/442306d2685b8f04bdd1db20cafdd283f5744c7ec42ba2be15a7ed2c29199b6a.jpg)

![6a287f04447062fa4398a7b5fd1971f15a14531152c65b5a46a1e8490204b1da.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/6a287f04447062fa4398a7b5fd1971f15a14531152c65b5a46a1e8490204b1da.jpg)

![6de7052218067761d90d9ab620557ed52298ef2f5eaac88d5ed4fd1a0f66cb0a.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/6de7052218067761d90d9ab620557ed52298ef2f5eaac88d5ed4fd1a0f66cb0a.jpg)

![75a156f753acef57dbff611463b89f8d9aba4e222034352d86bb93d2cf0e4911.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/75a156f753acef57dbff611463b89f8d9aba4e222034352d86bb93d2cf0e4911.jpg)

![9c79da224489f22d0e869e17d15188f1bf9345335d37915c14754c26816963f7.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/9c79da224489f22d0e869e17d15188f1bf9345335d37915c14754c26816963f7.jpg)

![b3645d47b98f416632e6e39fbaf136a624f44f2a28b9342eeeb59011454e80b5.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/b3645d47b98f416632e6e39fbaf136a624f44f2a28b9342eeeb59011454e80b5.jpg)

![b5d69147a18684b48ebe21c45ae7d79920787ba468b2098ee7422dd79c735d25.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/b5d69147a18684b48ebe21c45ae7d79920787ba468b2098ee7422dd79c735d25.jpg)

![b76b76a846720993c83b6d7ebb7ed24d15a685cb938629686358d4409fb311b7.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/b76b76a846720993c83b6d7ebb7ed24d15a685cb938629686358d4409fb311b7.jpg)

![c5f71a57da3457851585a566e8623e24d3e387f57b796462a285a9588694109c.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/c5f71a57da3457851585a566e8623e24d3e387f57b796462a285a9588694109c.jpg)

![dbbf0cb629996dbd5aa04428fe783189f5489d83a1c9ca414dfb7d93a5eb4835.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/dbbf0cb629996dbd5aa04428fe783189f5489d83a1c9ca414dfb7d93a5eb4835.jpg)

![e86b97efc24ae190b8332aa1394901f6c559b2b94bcf9bd2f71e1886618b4692.jpg](../iclr_results/783_Tree of Attributes Prompt Learning for Vision-Language Models/tables/e86b97efc24ae190b8332aa1394901f6c559b2b94bcf9bd2f71e1886618b4692.jpg)

## Expected Return Symmetries

### Images

![335a10153d2081873008a8af95dfb0b8edcbb97f12b8147b1ef33ffd4ccece14.jpg](../iclr_results/784_Expected Return Symmetries/images/335a10153d2081873008a8af95dfb0b8edcbb97f12b8147b1ef33ffd4ccece14.jpg)

![4f294ef07117accb455fc4acaa6fb878bd42207f5c5287c415a11357fb2048bb.jpg](../iclr_results/784_Expected Return Symmetries/images/4f294ef07117accb455fc4acaa6fb878bd42207f5c5287c415a11357fb2048bb.jpg)

![deaba5da43696e219a65d14342a5b6836f62c9b910f75d1c0a613cb5dee03d37.jpg](../iclr_results/784_Expected Return Symmetries/images/deaba5da43696e219a65d14342a5b6836f62c9b910f75d1c0a613cb5dee03d37.jpg)

### Tables

![3cf79891e34f490a733dafe7ca90ae5e3024b28f30af2a9df5034c9ce2f9568a.jpg](../iclr_results/784_Expected Return Symmetries/tables/3cf79891e34f490a733dafe7ca90ae5e3024b28f30af2a9df5034c9ce2f9568a.jpg)

![b0961e29db84202c77dcdc19ddbe098f14659df273c35e01bd3a40ae96277721.jpg](../iclr_results/784_Expected Return Symmetries/tables/b0961e29db84202c77dcdc19ddbe098f14659df273c35e01bd3a40ae96277721.jpg)

![fe6edb15da58635ea40b11b780bd1f6a46f18695b595553f2a941f4d01e98e4f.jpg](../iclr_results/784_Expected Return Symmetries/tables/fe6edb15da58635ea40b11b780bd1f6a46f18695b595553f2a941f4d01e98e4f.jpg)
